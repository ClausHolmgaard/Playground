{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y, y_hat, epsilon):\n",
    "    return y * (-np.log(y_hat + epsilon)) + (1-y) * (-np.log(1-y_hat + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "arr_x = np.array([[1, 0, 0],\n",
    "                  [0, 0, 0],\n",
    "                  [0, 1, 0]])\n",
    "\n",
    "arr_y = np.array([[0, 0, 0],\n",
    "                  [0, 0, 0],\n",
    "                  [0, 1, 1]])\n",
    "\n",
    "arr_m_x = np.zeros((2, 3, 3))\n",
    "arr_m_y = np.zeros((2, 3, 3))\n",
    "\n",
    "arr_m_x[0] = arr_x\n",
    "arr_m_x[1] = arr_x\n",
    "arr_m_y[0] = arr_y\n",
    "arr_m_y[1] = arr_y\n",
    "\n",
    "print(arr_x.shape)\n",
    "print(arr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.38155106e+01 -9.99999500e-07 -9.99999500e-07]\n",
      "  [-9.99999500e-07 -9.99999500e-07 -9.99999500e-07]\n",
      "  [-9.99999500e-07 -9.99999500e-07  1.38155106e+01]]\n",
      "\n",
      " [[ 1.38155106e+01 -9.99999500e-07 -9.99999500e-07]\n",
      "  [-9.99999500e-07 -9.99999500e-07 -9.99999500e-07]\n",
      "  [-9.99999500e-07 -9.99999500e-07  1.38155106e+01]]]\n"
     ]
    }
   ],
   "source": [
    "l = binary_crossentropy(arr_m_x, arr_m_y, 1e-6)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.26202823186409"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10)\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "r = range(10)\n",
    "print(r)\n",
    "for i in r[2+1::2]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loss_function_multiple_detection(anchor_width,\n",
    "                                            anchor_height,\n",
    "                                            label_weight,\n",
    "                                            offset_weight,\n",
    "                                            offset_loss_weight,\n",
    "                                            num_classes,\n",
    "                                            epsilon,\n",
    "                                            batchsize):\n",
    "    K = np\n",
    "    def loss_function(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Number of outputfilters is num_classes + 2*num_classes.\n",
    "        So the predicion output is batchsize x anchorwidth x anchorheight x (3 * num_classes)\n",
    "        \"\"\"\n",
    "        # number of labels\n",
    "        num_labels = num_classes  # TODO: If more labels are needed, this needs changing\n",
    "        num_non_labels = anchor_width * anchor_height - num_labels\n",
    "\n",
    "        # the first num_classes are confidence scores\n",
    "        c_labels = y_true[:, :, :, 0:num_classes]\n",
    "        c_predictions = y_pred[:, :, :, 0:num_classes]\n",
    "        \n",
    "        # And then we have the offsets\n",
    "        offset_labels = y_true[:, :, :, num_classes:]\n",
    "        offset_predictions = y_pred[:, :, :, num_classes:]\n",
    "\n",
    "        # First the confidence loss\n",
    "        c_loss = 0\n",
    "        # Loss matrix for all confidence entries\n",
    "        confidence_m_all = binary_crossentropy(c_labels, c_predictions, epsilon)\n",
    "        \n",
    "        # Loss matrix for the correct label\n",
    "        confidence_m_label = binary_crossentropy(c_labels, c_predictions, epsilon) * c_labels\n",
    "        \n",
    "        # Loss matrix for non labels\n",
    "        confidence_m_nonlabel = confidence_m_all - confidence_m_label\n",
    "        \n",
    "        # Summing and adding weight to label loss\n",
    "        c_loss_label = K.sum(\n",
    "            confidence_m_label\n",
    "        ) / num_labels\n",
    "        \n",
    "        # summing and adding weight to non label loss\n",
    "        c_loss_nonlabel = K.sum(\n",
    "            confidence_m_nonlabel\n",
    "        ) / num_non_labels\n",
    "        \n",
    "        c_loss += c_loss_label * label_weight + c_loss_nonlabel * (1 / label_weight)\n",
    "\n",
    "        # And then the offset loss\n",
    "        o_loss = 0\n",
    "        # Ground truth offsets\n",
    "        true_offset_x = offset_labels[:, :, :, num_classes::2]\n",
    "        true_offset_y = offset_labels[:, :, :, num_classes+1::2]\n",
    "\n",
    "        # Predicted labels, weighted so larger than 1 ouputs can be predicted\n",
    "        pred_offset_x = 2 * (offset_predictions[:, :, :, num_classes::2] - 0.5) * offset_weight\n",
    "        pred_offset_y = 2 * (offset_predictions[:, :, :, num_classes+1::2] - 0.5) * offset_weight\n",
    "        \n",
    "        # Create a mask of entries different from 0\n",
    "        g_x = K.less(true_offset_x, 0)\n",
    "        l_x = K.greater(true_offset_x, 0)\n",
    "        g_y = K.greater(true_offset_y, 0)\n",
    "        l_y = K.less(true_offset_y, 0)\n",
    "        \n",
    "        g_x_i = g_x.astype(np.float32)\n",
    "        l_x_i = l_x.astype(np.float32)\n",
    "        g_y_i = g_y.astype(np.float32)\n",
    "        l_y_i = l_y.astype(np.float32)\n",
    "\n",
    "        mask_offset_x = K.clip(g_x_i + l_x_i, 0, 1.0)\n",
    "        mask_offset_y = K.clip(g_y_i + l_y_i, 0, 1.0)\n",
    "        \n",
    "        o_loss_x = K.sum(\n",
    "            K.square((true_offset_x - pred_offset_x) * mask_offset_x)\n",
    "        ) / num_labels\n",
    "        \n",
    "        o_loss_y = K.sum(\n",
    "            K.square((true_offset_y - pred_offset_y) * mask_offset_y)\n",
    "        ) / num_labels\n",
    "        \n",
    "        o_loss += (o_loss_x + o_loss_y) * offset_loss_weight\n",
    "        \n",
    "        total_loss = (o_loss + c_loss)\n",
    "        \n",
    "        return total_loss\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_offset_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9454338eb590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_loss_function_multiple_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-ba93c10072ad>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Create a mask of entries different from 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_offset_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0ml_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_offset_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mg_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_offset_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_offset_x' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros((32, 320, 320, 6))\n",
    "y_true = np.zeros((32, 320, 320, 6))\n",
    "\n",
    "l = create_loss_function_multiple_detection(20, 20, 1.0, 1.0, 1.0, 6, 1e-6, 1)\n",
    "l(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
