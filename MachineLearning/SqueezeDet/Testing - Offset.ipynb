{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initially just some playing round with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Image<br>\n",
    "Initial output: center of hand<br>\n",
    "Is anchors needed? So the prediction is an offset?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SqueezeDetHelpers import fire_layer, binary_crossentropy, keras_binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grid over image size\n",
    "    - Grid nodes will be anchors\n",
    "    - Net predicts: Probability of class at anchor, and offset from anchor.\n",
    "        - In later versions, several offsets will be predicted at each offset.\n",
    "- The net is fully convolutional, meaning the output must be feature maps.\n",
    "    - Amount of output filters will then be confidence+x_offset+y_offset\n",
    "    - filter size will be the size of the anchor grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/annot\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"./data\"\n",
    "ANNOTATION_FILE = r\"annot\"\n",
    "annotation = os.path.join(DATA_DIR, ANNOTATION_FILE)\n",
    "print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 320\n",
    "WIDTH = 320\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_DECAY = 0 # 0.001\n",
    "KEEP_PROB = 0.5\n",
    "CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_HEIGHT = 20\n",
    "ANCHOR_WIDTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_WEIGHT = 1.0\n",
    "OFFSET_LOSS_WEIGHT = 1.0\n",
    "OFFSET_WEIGHT = 40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out dim: 20x20\n",
      "Number of anchor nodes: 400\n"
     ]
    }
   ],
   "source": [
    "num_anchor_nodes = ANCHOR_HEIGHT * ANCHOR_WIDTH\n",
    "\n",
    "print(f\"Out dim: {ANCHOR_HEIGHT}x{ANCHOR_WIDTH}\")\n",
    "print(f\"Number of anchor nodes: {num_anchor_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anchors: 400\n",
      "Anchor dimension: (20, 20)\n",
      "Anchor shape: (20, 20, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([45, 45], dtype=uint32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_anchors():\n",
    "    \n",
    "    #anchors = np.zeros((num_anchor_nodes, 2))\n",
    "    anchors = np.zeros((ANCHOR_HEIGHT, ANCHOR_WIDTH, 2), dtype=np.uint32)\n",
    "    print(f\"Number of anchors: {num_anchor_nodes}\")\n",
    "    \n",
    "    print(f\"Anchor dimension: ({ANCHOR_HEIGHT}, {ANCHOR_WIDTH})\")\n",
    "    print(f\"Anchor shape: {anchors.shape}\")\n",
    "    \n",
    "    #xs = np.arange(PIXELS_BETWEEN_ANCHORS, WIDTH, PIXELS_BETWEEN_ANCHORS)\n",
    "    #ys = np.arange(PIXELS_BETWEEN_ANCHORS, HEIGHT, PIXELS_BETWEEN_ANCHORS)\n",
    "    \n",
    "    x_start = WIDTH / (ANCHOR_WIDTH + 1)\n",
    "    x_end = WIDTH - x_start\n",
    "    y_start = HEIGHT / (ANCHOR_HEIGHT + 1)\n",
    "    y_end = HEIGHT - y_start\n",
    "    xs = np.linspace(x_start, x_end, num=ANCHOR_WIDTH, dtype=np.uint32)\n",
    "    ys = np.linspace(y_start, y_end, num=ANCHOR_HEIGHT, dtype=np.uint32)\n",
    "    \n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    for cx in range(len(xs)):\n",
    "        for cy in range(len(ys)):\n",
    "            anchors[counter] = [xs[cx], ys[cy]]\n",
    "            counter += 1\n",
    "    \"\"\"\n",
    "    \n",
    "    for ix in range(ANCHOR_HEIGHT):\n",
    "        for iy in range(ANCHOR_WIDTH):\n",
    "            anchors[ix, iy] = (xs[ix], ys[iy])\n",
    "    \n",
    "    return anchors\n",
    "    \n",
    "anchs = set_anchors()\n",
    "anchs[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (?, 320, 320, 3)\n",
      "conv1: (?, 160, 160, 128)\n",
      "pool1: (?, 80, 80, 128)\n",
      "fire1_1: (?, 80, 80, 256)\n",
      "fire1_2: (?, 80, 80, 256)\n",
      "pool2: (?, 40, 40, 256)\n",
      "fire2_1: (?, 40, 40, 384)\n",
      "fire2_2: (?, 40, 40, 384)\n",
      "pool3: (?, 20, 20, 384)\n",
      "fire3_1: (?, 20, 20, 384)\n",
      "fire3_2: (?, 20, 20, 384)\n",
      "pred_conf: (?, 20, 20, 1)\n",
      "pred_offset: (?, 20, 20, 2)\n",
      "preds: (?, 20, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name=\"input\")\n",
    "print(f\"input: {input_layer.shape}\")\n",
    "\n",
    "conv1 = Conv2D(name='conv1', filters=128, kernel_size=(3, 3), strides=(2, 2), activation=None, padding=\"SAME\",\n",
    "               use_bias=False,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(input_layer)\n",
    "print(f\"conv1: {conv1.shape}\")\n",
    "\n",
    "bn = BatchNormalization(name='bn')(conv1)\n",
    "act = Activation('relu', name='act')(bn)\n",
    "\n",
    "pool1 = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='SAME', name=\"pool1\")(act)\n",
    "print(f\"pool1: {pool1.shape}\")\n",
    "\n",
    "fire1_1 = fire_layer(name=\"fire1_1\", input=pool1, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire1_1: {fire1_1.shape}\")\n",
    "\n",
    "fire1_2 = fire_layer(name=\"fire1_2\", input=fire1_1, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire1_2: {fire1_2.shape}\")\n",
    "\n",
    "#fire1_3 = fire_layer(name=\"fire1_3\", input=fire1_2, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "#print(f\"fire1_3: {fire1_3.shape}\")\n",
    "\n",
    "pool2 = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='SAME', name=\"pool2\")(fire1_2)\n",
    "print(f\"pool2: {pool2.shape}\")\n",
    "\n",
    "fire2_1 = fire_layer(name=\"fire2_1\", input=pool2, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire2_1: {fire2_1.shape}\")\n",
    "\n",
    "fire2_2 = fire_layer(name=\"fire2_2\", input=fire2_1, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire2_2: {fire2_2.shape}\")\n",
    "\n",
    "#fire2_3 = fire_layer(name=\"fire2_3\", input=fire2_2, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "#print(f\"fire2_3: {fire2_3.shape}\")\n",
    "\n",
    "pool3 = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='SAME', name=\"pool3\")(fire2_2)\n",
    "print(f\"pool3: {pool3.shape}\")\n",
    "\n",
    "fire3_1 = fire_layer(name=\"fire3_1\", input=pool3, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire3_1: {fire3_1.shape}\")\n",
    "\n",
    "fire3_2 = fire_layer(name=\"fire3_2\", input=fire3_1, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire3_2: {fire3_2.shape}\")\n",
    "\n",
    "\"\"\"\n",
    "fire4 = fire_layer(name=\"fire4\", input=pool2, s1x1=16, e1x1=64, e3x3=64, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire4: {fire4.shape}\")\n",
    "\n",
    "fire5 = fire_layer(name=\"fire5\", input=fire4, s1x1=16, e1x1=64, e3x3=64, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire5: {fire5.shape}\")\n",
    "\n",
    "fire6 = fire_layer(name=\"fire6\", input=fire5, s1x1=16, e1x1=64, e3x3=64, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire6: {fire6.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "conv2 = Conv2D(name='conv2', filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(pool2)\n",
    "print(f\"conv2: {conv2.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "conv3 = Conv2D(name='conv3', filters=128, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(conv2)\n",
    "print(f\"conv3: {conv3.shape}\")\n",
    "\n",
    "conv4 = Conv2D(name='conv4', filters=256, kernel_size=(3, 3), strides=(2, 2), activation='relu', padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(conv3)\n",
    "print(f\"conv4: {conv4.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "preds = Conv2D(name='preds', filters=num_out, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(fire6)\n",
    "print(f\"preds: {preds.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "#drop1 = Dropout(rate=KEEP_PROB, name=\"drop1\")(fire6)\n",
    "\n",
    "pred_conf = Conv2D(name='pred_conf', filters=1, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(fire3_2)\n",
    "print(f\"pred_conf: {pred_conf.shape}\")\n",
    "\n",
    "pred_offset = Conv2D(name='pred_offset', filters=2, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(fire3_2)\n",
    "print(f\"pred_offset: {pred_offset.shape}\")\n",
    "\n",
    "#preds = Concatenate()([pred_conf, pred_offset])\n",
    "preds = concatenate([pred_conf, pred_offset])\n",
    "print(f\"preds: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross-entropy: q * -log(p) + (1-q) * -log(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    # We are predicting a batchsize x anchorwidth x anchorheight x 3 output.\n",
    "    c_predictions = y_pred[:, :, :, 0]\n",
    "    c_labels = y_true[:, :, :, 0]\n",
    "    \n",
    "    pred_offset_x = 2 * (y_pred[:, :, :, 1] - 0.5) * OFFSET_WEIGHT\n",
    "    pred_offset_y = 2 * (y_pred[:, :, :, 2] - 0.5) * OFFSET_WEIGHT\n",
    "    \n",
    "    true_offset_x = y_true[:, :, :, 1]\n",
    "    true_offset_y = y_true[:, :, :, 2]\n",
    "    \n",
    "    #offset_mask = K.copy(true_offset[:,:,:,0])\n",
    "    #offset_mask = K.abs(true_offset[:,:,:,0]) + K.abs(true_offset[:,:,:,0])\n",
    "    \n",
    "    #offset_mask[offset_mask!=0] = 1.0\n",
    "    \n",
    "    #offset_mask = K.zeros((BATCHSIZE, ANCHOR_WIDTH, ANCHOR_HEIGHT))\n",
    "    #m = K.where((true_offset[:,:,:,0]!=0) | (true_offset[:,:,:,1]!=0))\n",
    "    #offset_mask[true_offset[:,:,:,0]!=0] = 1.0\n",
    "    #offset_mask[true_offset[:,:,:,1]!=0] = 1.0\n",
    "    \n",
    "    g_x = K.less(true_offset_x, 0)\n",
    "    l_x = K.greater(true_offset_x, 0)\n",
    "    g_y = K.greater(true_offset_y, 0)\n",
    "    l_y = K.less(true_offset_y, 0)\n",
    "    \n",
    "    g_x_i = K.cast(g_x, dtype='float32')\n",
    "    l_x_i = K.cast(l_x, dtype='float32')\n",
    "    g_y_i = K.cast(g_y, dtype='float32')\n",
    "    l_y_i = K.cast(l_y, dtype='float32')\n",
    "\n",
    "    mask_offset_x = K.clip(g_x_i + l_x_i, 0, 1.0)\n",
    "    mask_offset_y = K.clip(g_y_i + l_y_i, 0, 1.0)\n",
    "    #zeroes = K.zeros_like(true_offset_x)\n",
    "    #ones = K.ones_like(true_offset_x)\n",
    "    #mask_offset = K.where(mask_offset_bool, ones, zeroes)\n",
    "    \n",
    "    #pred_conf = K.sigmoid(c_predictions)\n",
    "    #pred_conf = c_predictions\n",
    "\n",
    "    #c_loss = K.sum(\n",
    "    #    -(c_labels * K.log(pred_conf + EPSILON) + (1-c_labels) * K.log(1-pred_conf + EPSILON))\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    c_labels * (-K.log(c_predictions + EPSILON)) + (1-c_labels) * (-K.log(1-c_predictions + EPSILON)) * c_labels\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.maximum(K.abs(c_predictions), 0) - c_predictions * c_labels + K.log(1 + K.exp(-K.abs(c_predictions)))\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.maximum(K.abs(c_predictions), 0) - c_predictions * c_labels + K.log(1 + K.exp(-K.abs(c_predictions)))\n",
    "    #, axis=0) / BATCHSIZE\n",
    "\n",
    "    #c_loss = K.sum(c_loss) / (ANCHOR_HEIGHT * ANCHOR_WIDTH)\n",
    "    \n",
    "    #diff = K.abs(c_labels - c_predictions)\n",
    "    #c_loss = 2 * (K.sigmoid(diff) - 0.5)\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.sigmoid(\n",
    "    #        K.abs(\n",
    "    #            c_labels - c_predictions\n",
    "    #        )\n",
    "    #    )\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    2 * K.sigmoid(\n",
    "    #        K.abs(\n",
    "    #            c_labels - c_predictions\n",
    "    #        )\n",
    "    #    ) - 0.5\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.abs(\n",
    "    #        c_labels - c_predictions\n",
    "    #    )\n",
    "    #)\n",
    "    \n",
    "    \n",
    "    #c_loss = K.sig\n",
    "    \n",
    "    # number of labels\n",
    "    num_labels = K.sum(c_labels)  # Accounts for batch size\n",
    "    num_non_labels = ANCHOR_WIDTH * ANCHOR_HEIGHT - num_labels\n",
    "    \n",
    "    # Loss matrix for all entries\n",
    "    loss_m_all = keras_binary_crossentropy(c_labels, c_predictions, EPSILON)\n",
    "    \n",
    "    # Loss matrix for the correct label\n",
    "    loss_m_label = keras_binary_crossentropy(c_labels, c_predictions, EPSILON) * c_labels\n",
    "    \n",
    "    # Loss matrix for non labels\n",
    "    loss_m_nonlabel = loss_m_all - loss_m_label\n",
    "    \n",
    "    # Summing and adding weight to label loss\n",
    "    c_loss_label = K.sum(\n",
    "        loss_m_label\n",
    "    ) / num_labels\n",
    "    \n",
    "    # summing and adding weight to non label loss\n",
    "    c_loss_nonlabel = K.sum(\n",
    "        loss_m_nonlabel\n",
    "    ) / num_non_labels\n",
    "    \n",
    "    c_loss = c_loss_label * LABEL_WEIGHT + c_loss_nonlabel * (1 / LABEL_WEIGHT)\n",
    "    \n",
    "    \n",
    "    o_loss_x = K.sum(\n",
    "        #K.pow(true_offset_x - pred_offset_x, 2) * mask_offset_x\n",
    "        #K.abs(true_offset_x - pred_offset_x) * mask_offset_x\n",
    "        K.square((true_offset_x - pred_offset_x) * mask_offset_x)\n",
    "    ) / num_labels\n",
    "    \n",
    "    o_loss_y = K.sum(\n",
    "        #K.pow(true_offset_y - pred_offset_y, 2) * mask_offset_y\n",
    "        #K.abs(true_offset_y - pred_offset_y) * mask_offset_y\n",
    "        K.square((true_offset_y - pred_offset_y) * mask_offset_y)\n",
    "    ) / num_labels\n",
    "    \n",
    "    o_loss = (o_loss_x + o_loss_y) * OFFSET_LOSS_WEIGHT\n",
    "    \n",
    "    # Only on correct label\n",
    "    #o_loss = K.sum(\n",
    "    #    #K.pow(pred_offset - true_offset, 2) * offset_mask\n",
    "    #    (K.pow(\n",
    "    #        true_offset[:, :, :, 0] - pred_offset[:, :, :, 0], 2\n",
    "    #    ) + K.pow(\n",
    "    #        true_offset[:, :, :, 1] - pred_offset[:, :, :, 1], 2\n",
    "    #    ))# * offset_mask\n",
    "    #) / BATCHSIZE / num_labels\n",
    "    \n",
    "    #l2_loss = K.sum(\n",
    "    #    2 * K.sigmoid (\n",
    "    #        K.sqrt(\n",
    "    #            K.pow(y_true_offset[0] - y_true_offset[0], 2) + K.pow(y_true_offset[1] - y_pred_offset[1], 2)\n",
    "    #        )\n",
    "    #    ) - 0.5\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #l2_loss = K.sum(\n",
    "    #    2 * K.sigmoid(\n",
    "    #        K.pow(y_pred_offset - y_true_offset, 2)\n",
    "    #    ) - 0.5\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    \n",
    "    #o_loss = 0\n",
    "    \n",
    "    total_loss = o_loss + c_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "#y_true_test = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "#y_pred_test = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "#l = loss(y_pred_test, y_true_test)\n",
    "#print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0ded2c2208>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    sigm = 1. / (1. + np.exp(-x))\n",
    "    if derivative:\n",
    "        return sigm * (1. - sigm)\n",
    "    return sigm\n",
    "\n",
    "x = np.linspace(-10, 10, 500)\n",
    "y = 2 * (sigmoid(x) - 0.5)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$−(ylog(p)+(1−y)log(1−p))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/48951109/keras-custom-binary-cross-entropy-loss-function-get-nan-as-output-for-loss<br>\n",
    "$max(x, 0) - x * z + log(1 + exp(-abs(x)))$<br>\n",
    "$max(p, 0) - p * y + log(1 + exp(-abs(p)))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "c_labels = 1\n",
    "pred_conf = 0\n",
    "\n",
    "diff = abs(c_labels - pred_conf)\n",
    "l = (sigmoid(diff) - 0.5) * 2\n",
    "#print(l)\n",
    "\n",
    "#pred_conf = sigmoid(pred_conf)\n",
    "#ll = -(c_labels * np.log(pred_conf + EPSILON) + (1 - c_labels) * np.log(1-pred_conf + EPSILON))\n",
    "#print(ll)\n",
    "\n",
    "lll = np.max(np.abs(pred_conf), 0) - pred_conf * c_labels + np.log(1 + np.exp(-np.abs(pred_conf)))\n",
    "print(lll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 20, 20, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "y_t[:, 10, 10, 0] = 1.0\n",
    "print(y_t.shape)\n",
    "#np.max(np.maximum(-y_t, 0))\n",
    "np.sum(y_t) / BATCHSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "[[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([[1, 2, 3],\n",
    "                 [1, 2, 3],\n",
    "                 [1, 2, 3]])\n",
    "\n",
    "arr2 = np.array([[4, 5, 6],\n",
    "                 [4, 5, 6],\n",
    "                 [4, 5, 6]])\n",
    "\n",
    "res = np.concatenate((arr1, arr2), axis=-1)\n",
    "print(arr1.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label loss: 0.0\n",
      "Non label loss: 4.605170185988092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.605170185988092"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def np_loss(y_true, y_pred, bs):\n",
    "    #c_predictions = y_pred[:, :, :, 0]\n",
    "    #c_labels = y_true[:, :, :, 0]\n",
    "\n",
    "    c_predictions = y_pred\n",
    "    c_labels = y_true\n",
    "\n",
    "    \n",
    "    # number of labels\n",
    "    num_labels = np.sum(c_labels)\n",
    "    num_non_labels = 3 * 3 - num_labels   # ANCHOR_WIDTH and ANCHOR_HEIGHT\n",
    "    \n",
    "    # Loss matrix for all entries\n",
    "    loss_m_all = binary_crossentropy(c_labels, c_predictions, EPSILON)\n",
    "    \n",
    "    # Loss matrix for the correct label\n",
    "    loss_m_label = binary_crossentropy(c_labels, c_predictions, EPSILON) * c_labels\n",
    "    #print(loss_m_label)\n",
    "    \n",
    "    # Loss matrix for non labels\n",
    "    loss_m_nonlabel = loss_m_all - loss_m_label\n",
    "    #print(loss_m_nonlabel)\n",
    "    \n",
    "    # Summing and adding weight to label loss\n",
    "    c_loss_label = np.sum(\n",
    "        loss_m_label\n",
    "    ) / bs / num_labels\n",
    "    \n",
    "    # summing and adding weight to non label loss\n",
    "    c_loss_nonlabel = np.sum(\n",
    "        loss_m_nonlabel\n",
    "    ) / bs / num_non_labels\n",
    "    \n",
    "    print(f\"Label loss: {c_loss_label}\")\n",
    "    print(f\"Non label loss: {c_loss_nonlabel}\")\n",
    "    \n",
    "    c_loss = c_loss_label * LABEL_WEIGHT + c_loss_nonlabel * (1 / LABEL_WEIGHT)\n",
    "    \n",
    "    return c_loss\n",
    "\n",
    "\n",
    "#labels_test = np.copy(labels[-20:])\n",
    "#print(labels_test[:, :, :, 0].shape)\n",
    "#labels_test[:, :, :, 0] = 2\n",
    "#np_loss(labels[:20], labels_test)\n",
    "#print(np_loss(labels[-5:], labels[:5], 5))\n",
    "#print(np_loss(labels[:20], labels[:20], 20))\n",
    "\n",
    "\n",
    "true_test = np.array([[0, 0, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "pred_test = np.array([[0, 1, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "np_loss(true_test, pred_test, bs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith tf.Session() as s:\\n    # Some tensor we want to print the value of\\n    y_true_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\\n    y_pred_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\\n    s.run(tf.global_variables_initializer())\\n    \\n    l = loss(y_pred_test, y_true_test)\\n    # Add print operation\\n    print(s.run(l))\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "\n",
    "\"\"\"\n",
    "with tf.Session() as s:\n",
    "    # Some tensor we want to print the value of\n",
    "    y_true_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    y_pred_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    \n",
    "    l = loss(y_pred_test, y_true_test)\n",
    "    # Add print operation\n",
    "    print(s.run(l))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.841361487904734\n"
     ]
    }
   ],
   "source": [
    "c_labels = 0\n",
    "c_predictions = 1\n",
    "c_loss = (c_labels * (-np.log(c_predictions + EPSILON))) + (1-c_labels) * (-np.log(1-c_predictions + EPSILON))\n",
    "print(c_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Model(inputs=input_layer, outputs=preds)\n",
    "#model.compile(loss='mse', optimizer='adam')\n",
    "#model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    with open(annotation, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    gt = [(None, None)] * len(lines)\n",
    "    gt = np.zeros((len(lines), 2))\n",
    "    \n",
    "    for l in lines:\n",
    "        obj = l.split(',')\n",
    "        pic_id = int(obj[0].split('.')[0])\n",
    "        x = int(obj[1])\n",
    "        y = int(obj[2])\n",
    "        \n",
    "        gt[pic_id] = (x, y)\n",
    "\n",
    "    images = []\n",
    "    \n",
    "    for fi in os.listdir(DATA_DIR):\n",
    "        if not fi.endswith('jpg'):\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(DATA_DIR, fi))\n",
    "        images.append(im)\n",
    "    \n",
    "    return gt, images\n",
    "\n",
    "labels_clean, images_clean = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20, 3)\n",
      "1\n",
      "0.0125\n",
      "0.0\n",
      "[[1. 5. 0.]]\n",
      "(20, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "def closest_anchor_map(x, y, anchor_coords):\n",
    "    \"\"\" Create a anchor_height x anchor_width x 3 map.\n",
    "        First entry is 1 if the anchor point is closest to true point. Zero otherwise.\n",
    "        Second is x offset.\n",
    "        Third is y offset. \"\"\"\n",
    "    closest = 10000\n",
    "    closest_x = None\n",
    "    closest_y = None\n",
    "    closest_x_offset = None\n",
    "    closest_y_offset = None\n",
    "    \n",
    "    res = np.zeros((ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    for ix in range(ANCHOR_HEIGHT):\n",
    "        for iy in range(ANCHOR_WIDTH):\n",
    "            p_x, p_y = anchor_coords[ix, iy]\n",
    "            dist = np.sqrt( (x - p_x)**2 + (y - p_y)**2 )\n",
    "            #res[ix, iy, 1:] = (x - p_x, y - p_y)\n",
    "            if dist < closest:\n",
    "                closest = dist\n",
    "                closest_x = ix\n",
    "                closest_y = iy\n",
    "                closest_x_offset = (x - p_x)\n",
    "                closest_y_offset = (y - p_y)\n",
    "    \n",
    "    #print(f\"({closest_x}, {closest_y}) -> {anchor_coords[closest_x, closest_y]}\")\n",
    "    res[closest_x, closest_y, 0] = 1\n",
    "    res[closest_x, closest_y, 1:] = (closest_x_offset, closest_y_offset)\n",
    "    \n",
    "    return res\n",
    "        \n",
    "test_map = closest_anchor_map(20, 30, anchs)\n",
    "print(test_map.shape)\n",
    "print(np.count_nonzero(test_map[:,:, 0]))\n",
    "print(np.mean(test_map[:, :, 1]))\n",
    "print(np.mean(test_map[:, :, 2]))\n",
    "anc_indicies = np.where(test_map[:, :, 0] == test_map[:, :, 0].max())\n",
    "print(test_map[anc_indicies[0], anc_indicies[1]])\n",
    "anchor_point = test_map[anc_indicies[0], anc_indicies[1]][:,1:][0]\n",
    "print(anchs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d546f183abd64fab849ef017e0e6da6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a6340433d84d3397460d0f8ccc5614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1000, 20, 20, 3)\n",
      "float64\n",
      "300\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "def load_data_with_anchors():\n",
    "    # load images\n",
    "    # labels will be:\n",
    "    #   anchor_height x anchor_width x 3\n",
    "    #     the last 3 entries is: 1 if closest gridpoint to a point. x and y offsets to closest point.\n",
    "    with open(annotation, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    gt = np.zeros((len(lines), ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    gt_clean = [(None, None)] * len(lines)\n",
    "    images = np.zeros((len(lines), HEIGHT, WIDTH, 3))#, dtype=np.uint8)\n",
    "    \n",
    "    for c, l in enumerate(tqdm(lines)):\n",
    "        obj = l.split(',')\n",
    "        pic_id = int(obj[0].split('.')[0])\n",
    "        x = int(obj[1])\n",
    "        y = int(obj[2])\n",
    "        \n",
    "        gt[pic_id, :, :] = closest_anchor_map(x, y, anchs)\n",
    "        gt_clean[pic_id] = (x, y)\n",
    "    \n",
    "    #images = []\n",
    "    \n",
    "    for fi in tqdm(os.listdir(DATA_DIR)):\n",
    "        if not fi.endswith('jpg'):\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(DATA_DIR, fi))\n",
    "        #images.append(im)\n",
    "        i = int(fi.split('.')[0])\n",
    "        images[i] = im / 255.0\n",
    "    \n",
    "    images = np.array(images)\n",
    "    \n",
    "    return gt, gt_clean, images\n",
    "        \n",
    "labels, labels_clean, images = load_data_with_anchors()\n",
    "print(labels.shape)\n",
    "print(images[0].dtype)\n",
    "\n",
    "num_data = len(labels)\n",
    "num_validation_data = int(VALIDATION_SPLIT * num_data)\n",
    "validation_labels = labels[:num_validation_data]\n",
    "validation_images = images[:num_validation_data]\n",
    "labels = labels[num_validation_data:]\n",
    "images = images[num_validation_data:]\n",
    "\n",
    "print(len(validation_labels))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels[5][0][0])\n",
    "#np.max(images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check it everythin gets loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 137   91 -440  120]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 137,   91, -440,  120], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_points_from_prediction(pred, threshold=1.0, do_scale=True):\n",
    "    \"\"\"\n",
    "    pred is a prediction map in the shape (ANCHOR_HEIGHT, ANCHOR_WIDTH, 3)\n",
    "    \"\"\"\n",
    "    # Get all points with a confidence above threshold\n",
    "    label_indicies = np.where(pred[:, :, 0] >= threshold)\n",
    "    num_points = len(label_indicies[0])\n",
    "    #print(f\"max label index: {np.max(label_indicies)}\")\n",
    "    #print(f\"Values above threshold: {num_points}\")\n",
    "    \n",
    "    points = np.zeros((num_points, 4))#, dtype=np.int32)\n",
    "    \n",
    "    # Loop through all anchor points\n",
    "    for c, (x_anchor, y_anchor) in enumerate(zip(label_indicies[0], label_indicies[1])):\n",
    "        #print(x_anchor)\n",
    "        # when anchor location is known, the location of the closest anchor in the actual image can be found\n",
    "        x_without_offset, y_without_offset = anchs[x_anchor, y_anchor]\n",
    "        #print(f\"Anchor: ({x_anchor, y_anchor})\")\n",
    "        \n",
    "        # The offset can then be extracted from the labels\n",
    "        (x_offset, y_offset) = pred[label_indicies[0], label_indicies[1]][0][1:]\n",
    "        #print(f\"Raw offset: ({x_offset}, {y_offset})\")\n",
    "        if do_scale:\n",
    "            x_offset = 2 * (x_offset - 0.5) * OFFSET_WEIGHT\n",
    "            y_offset = 2 * (y_offset - 0.5) * OFFSET_WEIGHT\n",
    "        #print(f\"({x_offset}, {y_offset})\")\n",
    "        \n",
    "        # and the final point calculated\n",
    "        #actual_x = int(x_without_offset + x_offset)\n",
    "        #actual_y= int(y_without_offset + y_offset)\n",
    "\n",
    "        points[c] = (x_without_offset, y_without_offset, x_offset, y_offset)\n",
    "    \n",
    "    return points.astype(np.int32)\n",
    "    \n",
    "\n",
    "p = labels[0]\n",
    "#print(p.shape)\n",
    "pp = get_all_points_from_prediction(p)\n",
    "print(pp)\n",
    "print(\"\")\n",
    "pp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30 30]\n",
      "Max values in labels: 1\n",
      "Anchor: (137, 91)\n",
      "[[ 1. -5.  2.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Red is center, green is closest anchor')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "im = np.copy(images[index]) * 255.0\n",
    "#im = im.astype(np.uint8)\n",
    "\n",
    "im_anchors = np.copy(images[index]) * 255.0\n",
    "#im = im.astype(np.uint8)\n",
    "\n",
    "print(anchs[1, 1])\n",
    "\n",
    "# draw all anchors\n",
    "for anc_x in range(ANCHOR_HEIGHT):\n",
    "    for anc_y in range(ANCHOR_WIDTH):\n",
    "        cv2.circle(im_anchors, (anchs[anc_x, anc_y][0], anchs[anc_x, anc_y][1]), 1, (128, 128, 128), thickness=1)\n",
    "\n",
    "\n",
    "\n",
    "# Get labels with max value, we know this to only be one in the labels\n",
    "label_indicies = np.where(labels[index, :, :, 0] == labels[index, :, :, 0].max())\n",
    "print(f\"Max values in labels: {len(label_indicies[0])}\")\n",
    "\n",
    "# Get location in the anchor\n",
    "#x_anchor, y_anchor = label_indicies\n",
    "# when anchor location is known, the location of the closest anchor in the actual image can be found\n",
    "#x_without_offset, y_without_offset = anchs[x_anchor[0], y_anchor[0]]\n",
    "\"\"\"\n",
    "# The offset can then be extracted from the labels\n",
    "(x_offset, y_offset) = labels[index, label_indicies[0], label_indicies[1]][0][1:]\n",
    "# and the final point calculated\n",
    "actual_x = int(x_without_offset + x_offset)\n",
    "actual_y= int(y_without_offset + y_offset)\n",
    "print(f\"Actual point: ({actual_x}, {actual_y})\")\n",
    "\"\"\"\n",
    "actual_x_anch, actual_y_anch, actual_x_off, actual_y_off = get_all_points_from_prediction(labels[index],\n",
    "                                                                                          do_scale=False)[0]\n",
    "actual_point = (actual_x_anch + actual_x_off, actual_y_anch + actual_y_off)\n",
    "\n",
    "cv2.circle(im, (actual_y_anch, actual_x_anch), 2, (0, 255, 0), thickness=2)\n",
    "cv2.circle(im, (actual_point[1], actual_point[0]), 2, (255, 0, 0), thickness=2)\n",
    "print(f\"Anchor: ({actual_x_anch}, {actual_y_anch})\")\n",
    "print(labels[index, label_indicies[0], label_indicies[1]])\n",
    "\n",
    "f, subs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "subs[0].imshow(im_anchors.astype(np.uint8))\n",
    "subs[0].set_title(\"Anchor points\")\n",
    "subs[1].imshow(im.astype(np.uint8))\n",
    "subs[1].set_title(\"Red is center, green is closest anchor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = np.array(labels)#.reshape(1, 100, 2)\n",
    "#print(labels.shape)\n",
    "#print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c, i in enumerate(images):\n",
    "#    model.fit(i.reshape(1, 320, 320, 3), labels[c].reshape(1, 2), epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(images.reshape(-1, 320, 320, 3), labels.reshape(-1, 2), batch_size=10, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def loss(y_true, y_pred):\n",
    "#    return K.sqrt(K.sum(K.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintInfo(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        decay = self.model.optimizer.decay\n",
    "        iterations = self.model.optimizer.iterations\n",
    "        lr_with_decay = lr / (1. + decay * K.cast(iterations, K.dtype(decay)))\n",
    "        print(f\"Learning rate with decay: {K.eval(lr_with_decay)}\")\n",
    "        #print(f\"lr={K.eval(lr)}, decay={K.eval(decay)}\")\n",
    "        print(\"\")\n",
    "        \n",
    "print_info = PrintInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 320, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 160, 160, 128 3456        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 160, 160, 128 512         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "act (Activation)                (None, 160, 160, 128 0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 80, 80, 128)  0           act[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/squeeze1x1 (Conv2D)     (None, 80, 80, 32)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/bn1 (BatchNormalization (None, 80, 80, 32)   128         fire1_1/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/act1 (Activation)       (None, 80, 80, 32)   0           fire1_1/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/expand1x1 (Conv2D)      (None, 80, 80, 128)  4096        fire1_1/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/bn2 (BatchNormalization (None, 80, 80, 128)  512         fire1_1/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/act2 (Activation)       (None, 80, 80, 128)  0           fire1_1/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/expand3x3 (Conv2D)      (None, 80, 80, 128)  147584      fire1_1/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/bn3 (BatchNormalization (None, 80, 80, 128)  512         fire1_1/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/act3 (Activation)       (None, 80, 80, 128)  0           fire1_1/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80, 80, 256)  0           fire1_1/act2[0][0]               \n",
      "                                                                 fire1_1/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/squeeze1x1 (Conv2D)     (None, 80, 80, 32)   8192        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/bn1 (BatchNormalization (None, 80, 80, 32)   128         fire1_2/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/act1 (Activation)       (None, 80, 80, 32)   0           fire1_2/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/expand1x1 (Conv2D)      (None, 80, 80, 128)  4096        fire1_2/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/bn2 (BatchNormalization (None, 80, 80, 128)  512         fire1_2/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/act2 (Activation)       (None, 80, 80, 128)  0           fire1_2/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/expand3x3 (Conv2D)      (None, 80, 80, 128)  147584      fire1_2/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/bn3 (BatchNormalization (None, 80, 80, 128)  512         fire1_2/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/act3 (Activation)       (None, 80, 80, 128)  0           fire1_2/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 80, 80, 256)  0           fire1_2/act2[0][0]               \n",
      "                                                                 fire1_2/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 40, 40, 256)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/squeeze1x1 (Conv2D)     (None, 40, 40, 48)   12288       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/bn1 (BatchNormalization (None, 40, 40, 48)   192         fire2_1/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/act1 (Activation)       (None, 40, 40, 48)   0           fire2_1/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/expand1x1 (Conv2D)      (None, 40, 40, 192)  9216        fire2_1/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/bn2 (BatchNormalization (None, 40, 40, 192)  768         fire2_1/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/act2 (Activation)       (None, 40, 40, 192)  0           fire2_1/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/expand3x3 (Conv2D)      (None, 40, 40, 192)  331968      fire2_1/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/bn3 (BatchNormalization (None, 40, 40, 192)  768         fire2_1/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/act3 (Activation)       (None, 40, 40, 192)  0           fire2_1/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 40, 40, 384)  0           fire2_1/act2[0][0]               \n",
      "                                                                 fire2_1/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/squeeze1x1 (Conv2D)     (None, 40, 40, 48)   18432       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/bn1 (BatchNormalization (None, 40, 40, 48)   192         fire2_2/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/act1 (Activation)       (None, 40, 40, 48)   0           fire2_2/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/expand1x1 (Conv2D)      (None, 40, 40, 192)  9216        fire2_2/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/bn2 (BatchNormalization (None, 40, 40, 192)  768         fire2_2/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/act2 (Activation)       (None, 40, 40, 192)  0           fire2_2/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/expand3x3 (Conv2D)      (None, 40, 40, 192)  331968      fire2_2/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/bn3 (BatchNormalization (None, 40, 40, 192)  768         fire2_2/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/act3 (Activation)       (None, 40, 40, 192)  0           fire2_2/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 40, 40, 384)  0           fire2_2/act2[0][0]               \n",
      "                                                                 fire2_2/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 20, 20, 384)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/squeeze1x1 (Conv2D)     (None, 20, 20, 48)   18432       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/bn1 (BatchNormalization (None, 20, 20, 48)   192         fire3_1/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/act1 (Activation)       (None, 20, 20, 48)   0           fire3_1/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/expand1x1 (Conv2D)      (None, 20, 20, 192)  9216        fire3_1/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/bn2 (BatchNormalization (None, 20, 20, 192)  768         fire3_1/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/act2 (Activation)       (None, 20, 20, 192)  0           fire3_1/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/expand3x3 (Conv2D)      (None, 20, 20, 192)  331968      fire3_1/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/bn3 (BatchNormalization (None, 20, 20, 192)  768         fire3_1/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/act3 (Activation)       (None, 20, 20, 192)  0           fire3_1/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 20, 20, 384)  0           fire3_1/act2[0][0]               \n",
      "                                                                 fire3_1/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/squeeze1x1 (Conv2D)     (None, 20, 20, 48)   18432       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/bn1 (BatchNormalization (None, 20, 20, 48)   192         fire3_2/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/act1 (Activation)       (None, 20, 20, 48)   0           fire3_2/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/expand1x1 (Conv2D)      (None, 20, 20, 192)  9216        fire3_2/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/bn2 (BatchNormalization (None, 20, 20, 192)  768         fire3_2/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/act2 (Activation)       (None, 20, 20, 192)  0           fire3_2/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/expand3x3 (Conv2D)      (None, 20, 20, 192)  331968      fire3_2/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/bn3 (BatchNormalization (None, 20, 20, 192)  768         fire3_2/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/act3 (Activation)       (None, 20, 20, 192)  0           fire3_2/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 20, 20, 384)  0           fire3_2/act2[0][0]               \n",
      "                                                                 fire3_2/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pred_conf (Conv2D)              (None, 20, 20, 1)    385         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pred_offset (Conv2D)            (None, 20, 20, 2)    770         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 20, 20, 3)    0           pred_conf[0][0]                  \n",
      "                                                                 pred_offset[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,762,307\n",
      "Trainable params: 1,757,443\n",
      "Non-trainable params: 4,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=1e-4, decay=1e-4) #, clipnorm=1.0)\n",
    "#opt = optimizers.RMSprop(lr=0.001)#,  clipnorm=1.0)\n",
    "#opt = optimizers.SGD(lr=0.01, decay=0.001, momentum=0.9, nesterov=False)\n",
    "#opt = optimizers.Adagrad(lr=1e-3, decay=1e-3, clipnorm=1.0)\n",
    "#opt =optimizers.SGD()\n",
    "model.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 15.1891\n",
      "Learning rate with decay: 9.846396278589964e-05\n",
      "\n",
      "Epoch 2/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 13.6291\n",
      "Learning rate with decay: 9.803921420825645e-05\n",
      "\n",
      "Epoch 3/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 11.3660\n",
      "Learning rate with decay: 9.761811816133559e-05\n",
      "\n",
      "Epoch 4/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 9.9306\n",
      "Learning rate with decay: 9.720061643747613e-05\n",
      "\n",
      "Epoch 5/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 9.3681\n",
      "Learning rate with decay: 9.678667993284762e-05\n",
      "\n",
      "Epoch 6/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 8.8117\n",
      "Learning rate with decay: 9.637624316383153e-05\n",
      "\n",
      "Epoch 7/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 7.9411\n",
      "Learning rate with decay: 9.596928430255502e-05\n",
      "\n",
      "Epoch 8/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 6.8406\n",
      "Learning rate with decay: 9.55657524173148e-05\n",
      "\n",
      "Epoch 9/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 6.0387\n",
      "Learning rate with decay: 9.516558930044994e-05\n",
      "\n",
      "Epoch 10/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 6.4539\n",
      "Learning rate with decay: 9.476876584812999e-05\n",
      "\n",
      "Epoch 11/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 5.4838\n",
      "Learning rate with decay: 9.437523112865165e-05\n",
      "\n",
      "Epoch 12/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 5.5564\n",
      "Learning rate with decay: 9.398495603818446e-05\n",
      "\n",
      "Epoch 13/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 4.9969\n",
      "Learning rate with decay: 9.359789692098275e-05\n",
      "\n",
      "Epoch 14/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 4.4232\n",
      "Learning rate with decay: 9.321401012130082e-05\n",
      "\n",
      "Epoch 15/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 4.9528\n",
      "Learning rate with decay: 9.283327381126583e-05\n",
      "\n",
      "Epoch 16/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 3.9745\n",
      "Learning rate with decay: 9.245562250725925e-05\n",
      "\n",
      "Epoch 17/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 3.7543\n",
      "Learning rate with decay: 9.208103438140824e-05\n",
      "\n",
      "Epoch 18/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 3.2784\n",
      "Learning rate with decay: 9.170946577796713e-05\n",
      "\n",
      "Epoch 19/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 3.5049\n",
      "Learning rate with decay: 9.134088031714782e-05\n",
      "\n",
      "Epoch 20/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 3.3715\n",
      "Learning rate with decay: 9.097524889511988e-05\n",
      "\n",
      "Epoch 21/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 2.9193\n",
      "Learning rate with decay: 9.061253513209522e-05\n",
      "\n",
      "Epoch 22/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 2.5210\n",
      "Learning rate with decay: 9.025270264828578e-05\n",
      "\n",
      "Epoch 23/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 2.6154\n",
      "Learning rate with decay: 8.989571506390348e-05\n",
      "\n",
      "Epoch 24/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 2.2346\n",
      "Learning rate with decay: 8.954155055107549e-05\n",
      "\n",
      "Epoch 25/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 1.9613\n",
      "Learning rate with decay: 8.919015090214089e-05\n",
      "\n",
      "Epoch 26/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 2.1178\n",
      "Learning rate with decay: 8.884150884114206e-05\n",
      "\n",
      "Epoch 27/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 1.9354\n",
      "Learning rate with decay: 8.849557343637571e-05\n",
      "\n",
      "Epoch 28/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 2.0748\n",
      "Learning rate with decay: 8.815232285996899e-05\n",
      "\n",
      "Epoch 29/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.5784\n",
      "Learning rate with decay: 8.781172800809145e-05\n",
      "\n",
      "Epoch 30/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.4691\n",
      "Learning rate with decay: 8.747375250095502e-05\n",
      "\n",
      "Epoch 31/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.3969\n",
      "Learning rate with decay: 8.713838178664446e-05\n",
      "\n",
      "Epoch 32/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.3423\n",
      "Learning rate with decay: 8.680555765749887e-05\n",
      "\n",
      "Epoch 33/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.3727\n",
      "Learning rate with decay: 8.647526556160301e-05\n",
      "\n",
      "Epoch 34/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.3130\n",
      "Learning rate with decay: 8.614748367108405e-05\n",
      "\n",
      "Epoch 35/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.3859\n",
      "Learning rate with decay: 8.58221756061539e-05\n",
      "\n",
      "Epoch 36/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.1969\n",
      "Learning rate with decay: 8.549931226298213e-05\n",
      "\n",
      "Epoch 37/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.1126\n",
      "Learning rate with decay: 8.517887181369588e-05\n",
      "\n",
      "Epoch 38/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.1944\n",
      "Learning rate with decay: 8.486082515446469e-05\n",
      "\n",
      "Epoch 39/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.1347\n",
      "Learning rate with decay: 8.454514318145812e-05\n",
      "\n",
      "Epoch 40/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.1518\n",
      "Learning rate with decay: 8.42318040668033e-05\n",
      "\n",
      "Epoch 41/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.2093\n",
      "Learning rate with decay: 8.392077870666981e-05\n",
      "\n",
      "Epoch 42/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.2218\n",
      "Learning rate with decay: 8.361203799722716e-05\n",
      "\n",
      "Epoch 43/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.2183\n",
      "Learning rate with decay: 8.330556011060253e-05\n",
      "\n",
      "Epoch 44/100000\n",
      "700/700 [==============================] - 25s 35ms/step - loss: 1.3309\n",
      "Learning rate with decay: 8.300132321892306e-05\n",
      "\n",
      "Epoch 45/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.3136\n",
      "Learning rate with decay: 8.269929821835831e-05\n",
      "\n",
      "Epoch 46/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.1662\n",
      "Learning rate with decay: 8.239947055699304e-05\n",
      "\n",
      "Epoch 47/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.0992\n",
      "Learning rate with decay: 8.21018111309968e-05\n",
      "\n",
      "Epoch 48/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 1.0796\n",
      "Learning rate with decay: 8.18062835605815e-05\n",
      "\n",
      "Epoch 49/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.9512\n",
      "Learning rate with decay: 8.151288056978956e-05\n",
      "\n",
      "Epoch 50/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.8325\n",
      "Learning rate with decay: 8.12215730547905e-05\n",
      "\n",
      "Epoch 51/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.8554\n",
      "Learning rate with decay: 8.093233918771148e-05\n",
      "\n",
      "Epoch 52/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.7642\n",
      "Learning rate with decay: 8.064515714067966e-05\n",
      "\n",
      "Epoch 53/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.6817\n",
      "Learning rate with decay: 8.036001236177981e-05\n",
      "\n",
      "Epoch 54/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.6866\n",
      "Learning rate with decay: 8.007686847122386e-05\n",
      "\n",
      "Epoch 55/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.6372\n",
      "Learning rate with decay: 7.97957181930542e-05\n",
      "\n",
      "Epoch 56/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.7020\n",
      "Learning rate with decay: 7.951653969939798e-05\n",
      "\n",
      "Epoch 57/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.6637\n",
      "Learning rate with decay: 7.923930388642475e-05\n",
      "\n",
      "Epoch 58/100000\n",
      "700/700 [==============================] - 24s 35ms/step - loss: 0.7173\n",
      "Learning rate with decay: 7.896398892626166e-05\n",
      "\n",
      "Epoch 59/100000\n",
      " 16/700 [..............................] - ETA: 23s - loss: 0.5835"
     ]
    }
   ],
   "source": [
    "#model.fit(images.reshape(-1, 320, 320, 3), labels.reshape(-1, 2), batch_size=10, epochs=10, verbose=1)\n",
    "model.fit(images.reshape(-1, 320, 320, 3),\n",
    "          labels.reshape(-1, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3),\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=1000,\n",
    "          verbose=1,\n",
    "          callbacks=[print_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_IMAGE_INDEX = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass time: 0.02056741714477539\n"
     ]
    }
   ],
   "source": [
    "before = time.time()\n",
    "res = model.predict(images[CHECK_IMAGE_INDEX].reshape(1, 320, 320, 3)).reshape(ANCHOR_HEIGHT, ANCHOR_WIDTH, 3)\n",
    "after = time.time()\n",
    "print(f\"Forward pass time: {after-before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indicies = np.where(res[:,:,0] == res[:,:,0].max())\n",
    "#print(indicies)\n",
    "print(f\"Max values found: {len(indicies[0])}\")\n",
    "print(res[indicies[0][0], indicies[1][0], 0])\n",
    "#print(res[indicies[0][5], indicies[1][5], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indicies = np.where(labels[CHECK_IMAGE_INDEX, :, :, 0] == labels[CHECK_IMAGE_INDEX, :, :, 0].max())\n",
    "print(f\"Max values in labels: {len(label_indicies[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of anchors: {ANCHOR_WIDTH * ANCHOR_HEIGHT}\")\n",
    "max_val = np.max(res[:, :, 0])\n",
    "print(f\"Max value: {max_val}\")\n",
    "above_val = max_val\n",
    "print(f\"Number of values above or equal to {above_val}: {np.count_nonzero(res[:, :, 0] >= above_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copy the image, so we don't change anything\n",
    "im_res = np.copy(images[CHECK_IMAGE_INDEX])\n",
    "im_res *= 255.0\n",
    "im_res = im_res.astype(np.uint8)\n",
    "\n",
    "for x_res, y_res, x_offset, y_offset in get_all_points_from_prediction(res, threshold=above_val):\n",
    "    prediction_x = x_res + x_offset\n",
    "    prediction_y = y_res + y_offset\n",
    "    cv2.circle(im_res, (prediction_y, prediction_x), 1, (0, 255, 0), thickness=2)\n",
    "    print(f\"Predicted point(green) anchor: ({x_res}, {y_res}), offset: ({x_offset}, {y_offset})\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "x_actual, y_actual, x_act_offset, y_act_offset = get_all_points_from_prediction(labels[CHECK_IMAGE_INDEX],\n",
    "                                                                                do_scale=False)[0]\n",
    "x_label_point = (x_actual + x_act_offset, y_actual + y_act_offset)\n",
    "cv2.circle(im_res, (x_label_point[1], x_label_point[0]), 1, (255, 0, 0), thickness=2)\n",
    "print(f\"Center(red) point anchor: ({x_actual}, {y_actual}), offset: ({x_act_offset}, {y_act_offset})\")\n",
    "\n",
    "f = plt.figure(figsize=(15, 8))\n",
    "plt.imshow(im_res)\n",
    "plt.title(\"Predicted in green, center in red.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_x = res[:, :, 1]\n",
    "res_y = res[:, :, 2]\n",
    "\n",
    "print(f\"Max x prediction: {np.max(res_x)}, min x prediction: {np.min(res_x)}\")\n",
    "print(f\"Max y prediction: {np.max(res_y)}, min y prediction: {np.min(res_y)}\")\n",
    "\n",
    "f, subs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "subs[0].imshow(res_x, cmap='gray')\n",
    "subs[0].set_title(\"X offset predictions\")\n",
    "subs[1].imshow(res_y, cmap='gray')\n",
    "subs[1].set_title(\"Y offset prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "print(layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_from_filterdata(filter_data):\n",
    "    if(np.min(filter_data) < 0):\n",
    "        filter_data = filter_data - np.min(filter_data)\n",
    "\n",
    "    filter_data = (filter_data - np.min(filter_data)) / (np.max(filter_data) - np.min(filter_data))\n",
    "    filter_data_gray = np.zeros((filter_data.shape[0], filter_data.shape[1]))\n",
    "    filter_data_gray = np.mean(filter_data, axis=2)\n",
    "    \n",
    "    return filter_data_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layer_name = \"conv1\"\n",
    "num_filters = 32\n",
    "\n",
    "col_plots = 4\n",
    "row_plots = int(np.ceil(num_filters / 4))\n",
    "\n",
    "f, subs = plt.subplots(row_plots, col_plots, figsize=(15, 4*row_plots))\n",
    "subs = subs.ravel()\n",
    "\n",
    "layer_output = layer_dict[layer_name].output\n",
    "\n",
    "for i in range(num_filters):\n",
    "    #filter_weights = layer_output[:, :, :, i]\n",
    "    filters = layer_dict[layer_name].get_weights()[0]\n",
    "    filter_index_data = filters[:, :, :, i]\n",
    "    filter_index_gray = get_image_from_filterdata(filter_index_data)\n",
    "\n",
    "    subs[i].imshow(filter_index_gray, cmap='gray')\n",
    "    subs[i].set_title(f\"Filter {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data, labels):\n",
    "    \n",
    "    error = 0\n",
    "    min_error = None\n",
    "    max_error = None\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        p = model.predict(data[i].reshape(1, 320, 320, 3)).reshape(ANCHOR_HEIGHT, ANCHOR_WIDTH, 3)\n",
    "        \n",
    "        # Note, only using first point\n",
    "        predicted_points = get_all_points_from_prediction(p, threshold=np.max(p[:, :, 0]))[0]\n",
    "        predicted_x = predicted_points[0] + predicted_points[2]\n",
    "        predicted_y = predicted_points[1] + predicted_points[3]\n",
    "\n",
    "        label_point = get_all_points_from_prediction(labels[i], do_scale=False)[0]\n",
    "        label_x = label_point[0] + label_point[2]\n",
    "        label_y = label_point[1] + label_point[3]\n",
    "        \n",
    "        dist = np.sqrt((predicted_x - label_x)**2 + (predicted_y - label_y)**2)\n",
    "        #print(f\"{i}: {dist}, ({label_x}, {label_y}) -> ({predicted_x}, {predicted_y})\")\n",
    "        \n",
    "        if min_error is None:\n",
    "            min_error = dist\n",
    "        else:\n",
    "            if dist < min_error:\n",
    "                min_error = dist\n",
    "                \n",
    "        if max_error is None:\n",
    "            max_error = dist\n",
    "        else:\n",
    "            if dist > max_error:\n",
    "                max_error = dist\n",
    "        \n",
    "        error += dist\n",
    "\n",
    "    error /= (i+1)\n",
    "    \n",
    "    return error, min_error, max_error\n",
    "    \n",
    "e, min_e, max_e = accuracy(validation_images, validation_labels)\n",
    "print(f\"Average error: {e}\")\n",
    "print(f\"min error: {min_e}\")\n",
    "print(f\"max error: {max_e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
