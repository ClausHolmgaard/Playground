{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initially just some playing round with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Image<br>\n",
    "Initial output: center of hand<br>\n",
    "Is anchors needed? So the prediction is an offset?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SqueezeDetHelpers import fire_layer, binary_crossentropy, keras_binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grid over image size\n",
    "    - Grid nodes will be anchors\n",
    "    - Net predicts: Probability of class at anchor, and offset from anchor.\n",
    "        - In later versions, several offsets will be predicted at each offset.\n",
    "- The net is fully convolutional, meaning the output must be feature maps.\n",
    "    - Amount of output filters will then be confidence+x_offset+y_offset\n",
    "    - filter size will be the size of the anchor grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/annot\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"./data\"\n",
    "ANNOTATION_FILE = r\"annot\"\n",
    "annotation = os.path.join(DATA_DIR, ANNOTATION_FILE)\n",
    "print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 320\n",
    "WIDTH = 320\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_DECAY = 0 # 0.001\n",
    "KEEP_PROB = 0.5\n",
    "CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_HEIGHT = 20\n",
    "ANCHOR_WIDTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_WEIGHT = 1.0\n",
    "OFFSET_LOSS_WEIGHT = 1.0\n",
    "OFFSET_WEIGHT = 40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out dim: 20x20\n",
      "Number of anchor nodes: 400\n"
     ]
    }
   ],
   "source": [
    "num_anchor_nodes = ANCHOR_HEIGHT * ANCHOR_WIDTH\n",
    "\n",
    "print(f\"Out dim: {ANCHOR_HEIGHT}x{ANCHOR_WIDTH}\")\n",
    "print(f\"Number of anchor nodes: {num_anchor_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anchors: 400\n",
      "Anchor dimension: (20, 20)\n",
      "Anchor shape: (20, 20, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([45, 45], dtype=uint32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_anchors():\n",
    "    \n",
    "    #anchors = np.zeros((num_anchor_nodes, 2))\n",
    "    anchors = np.zeros((ANCHOR_HEIGHT, ANCHOR_WIDTH, 2), dtype=np.uint32)\n",
    "    print(f\"Number of anchors: {num_anchor_nodes}\")\n",
    "    \n",
    "    print(f\"Anchor dimension: ({ANCHOR_HEIGHT}, {ANCHOR_WIDTH})\")\n",
    "    print(f\"Anchor shape: {anchors.shape}\")\n",
    "    \n",
    "    #xs = np.arange(PIXELS_BETWEEN_ANCHORS, WIDTH, PIXELS_BETWEEN_ANCHORS)\n",
    "    #ys = np.arange(PIXELS_BETWEEN_ANCHORS, HEIGHT, PIXELS_BETWEEN_ANCHORS)\n",
    "    \n",
    "    x_start = WIDTH / (ANCHOR_WIDTH + 1)\n",
    "    x_end = WIDTH - x_start\n",
    "    y_start = HEIGHT / (ANCHOR_HEIGHT + 1)\n",
    "    y_end = HEIGHT - y_start\n",
    "    xs = np.linspace(x_start, x_end, num=ANCHOR_WIDTH, dtype=np.uint32)\n",
    "    ys = np.linspace(y_start, y_end, num=ANCHOR_HEIGHT, dtype=np.uint32)\n",
    "    \n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    for cx in range(len(xs)):\n",
    "        for cy in range(len(ys)):\n",
    "            anchors[counter] = [xs[cx], ys[cy]]\n",
    "            counter += 1\n",
    "    \"\"\"\n",
    "    \n",
    "    for ix in range(ANCHOR_HEIGHT):\n",
    "        for iy in range(ANCHOR_WIDTH):\n",
    "            anchors[ix, iy] = (xs[ix], ys[iy])\n",
    "    \n",
    "    return anchors\n",
    "    \n",
    "anchs = set_anchors()\n",
    "anchs[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (?, 320, 320, 3)\n",
      "conv1: (?, 160, 160, 128)\n",
      "pool1: (?, 80, 80, 128)\n",
      "fire1_1: (?, 80, 80, 256)\n",
      "fire1_2: (?, 80, 80, 256)\n",
      "pool2: (?, 40, 40, 256)\n",
      "fire2_1: (?, 40, 40, 384)\n",
      "fire2_2: (?, 40, 40, 384)\n",
      "pool3: (?, 20, 20, 384)\n",
      "fire3_1: (?, 20, 20, 384)\n",
      "fire3_2: (?, 20, 20, 384)\n",
      "pred_conf: (?, 20, 20, 1)\n",
      "pred_offset: (?, 20, 20, 2)\n",
      "preds: (?, 20, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name=\"input\")\n",
    "print(f\"input: {input_layer.shape}\")\n",
    "\n",
    "conv1 = Conv2D(name='conv1', filters=128, kernel_size=(2, 2), strides=(2, 2), activation=None, padding=\"SAME\",\n",
    "               use_bias=False,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(input_layer)\n",
    "print(f\"conv1: {conv1.shape}\")\n",
    "\n",
    "bn = BatchNormalization(name='bn')(conv1)\n",
    "act = Activation('relu', name='act')(bn)\n",
    "\n",
    "pool1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='SAME', name=\"pool1\")(act)\n",
    "print(f\"pool1: {pool1.shape}\")\n",
    "\n",
    "fire1_1 = fire_layer(name=\"fire1_1\", input=pool1, s1x1=32, e1x1=128, e3x3=128)\n",
    "print(f\"fire1_1: {fire1_1.shape}\")\n",
    "\n",
    "fire1_2 = fire_layer(name=\"fire1_2\", input=fire1_1, s1x1=32, e1x1=128, e3x3=128)\n",
    "print(f\"fire1_2: {fire1_2.shape}\")\n",
    "\n",
    "#fire1_3 = fire_layer(name=\"fire1_3\", input=fire1_2, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "#print(f\"fire1_3: {fire1_3.shape}\")\n",
    "\n",
    "pool2 = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='SAME', name=\"pool2\")(fire1_2)\n",
    "print(f\"pool2: {pool2.shape}\")\n",
    "\n",
    "fire2_1 = fire_layer(name=\"fire2_1\", input=pool2, s1x1=48, e1x1=192, e3x3=192)\n",
    "print(f\"fire2_1: {fire2_1.shape}\")\n",
    "\n",
    "fire2_2 = fire_layer(name=\"fire2_2\", input=fire2_1, s1x1=48, e1x1=192, e3x3=192)\n",
    "print(f\"fire2_2: {fire2_2.shape}\")\n",
    "\n",
    "#fire2_3 = fire_layer(name=\"fire2_3\", input=fire2_2, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "#print(f\"fire2_3: {fire2_3.shape}\")\n",
    "\n",
    "pool3 = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='SAME', name=\"pool3\")(fire2_2)\n",
    "print(f\"pool3: {pool3.shape}\")\n",
    "\n",
    "fire3_1 = fire_layer(name=\"fire3_1\", input=pool3, s1x1=48, e1x1=192, e3x3=192)\n",
    "print(f\"fire3_1: {fire3_1.shape}\")\n",
    "\n",
    "fire3_2 = fire_layer(name=\"fire3_2\", input=fire3_1, s1x1=48, e1x1=192, e3x3=192)\n",
    "print(f\"fire3_2: {fire3_2.shape}\")\n",
    "\n",
    "\"\"\"\n",
    "fire4 = fire_layer(name=\"fire4\", input=pool2, s1x1=16, e1x1=64, e3x3=64, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire4: {fire4.shape}\")\n",
    "\n",
    "fire5 = fire_layer(name=\"fire5\", input=fire4, s1x1=16, e1x1=64, e3x3=64, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire5: {fire5.shape}\")\n",
    "\n",
    "fire6 = fire_layer(name=\"fire6\", input=fire5, s1x1=16, e1x1=64, e3x3=64, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire6: {fire6.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "conv2 = Conv2D(name='conv2', filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(pool2)\n",
    "print(f\"conv2: {conv2.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "conv3 = Conv2D(name='conv3', filters=128, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(conv2)\n",
    "print(f\"conv3: {conv3.shape}\")\n",
    "\n",
    "conv4 = Conv2D(name='conv4', filters=256, kernel_size=(3, 3), strides=(2, 2), activation='relu', padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(conv3)\n",
    "print(f\"conv4: {conv4.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "preds = Conv2D(name='preds', filters=num_out, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(fire6)\n",
    "print(f\"preds: {preds.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "#drop1 = Dropout(rate=KEEP_PROB, name=\"drop1\")(fire6)\n",
    "\n",
    "pred_conf = Conv2D(name='pred_conf', filters=1, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(fire3_2)\n",
    "print(f\"pred_conf: {pred_conf.shape}\")\n",
    "\n",
    "pred_offset = Conv2D(name='pred_offset', filters=2, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(fire3_2)\n",
    "print(f\"pred_offset: {pred_offset.shape}\")\n",
    "\n",
    "#preds = Concatenate()([pred_conf, pred_offset])\n",
    "preds = concatenate([pred_conf, pred_offset])\n",
    "print(f\"preds: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross-entropy: q * -log(p) + (1-q) * -log(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    # We are predicting a batchsize x anchorwidth x anchorheight x 3 output.\n",
    "    c_predictions = y_pred[:, :, :, 0]\n",
    "    c_labels = y_true[:, :, :, 0]\n",
    "    \n",
    "    pred_offset_x = 2 * (y_pred[:, :, :, 1] - 0.5) * OFFSET_WEIGHT\n",
    "    pred_offset_y = 2 * (y_pred[:, :, :, 2] - 0.5) * OFFSET_WEIGHT\n",
    "    \n",
    "    true_offset_x = y_true[:, :, :, 1]\n",
    "    true_offset_y = y_true[:, :, :, 2]\n",
    "    \n",
    "    #offset_mask = K.copy(true_offset[:,:,:,0])\n",
    "    #offset_mask = K.abs(true_offset[:,:,:,0]) + K.abs(true_offset[:,:,:,0])\n",
    "    \n",
    "    #offset_mask[offset_mask!=0] = 1.0\n",
    "    \n",
    "    #offset_mask = K.zeros((BATCHSIZE, ANCHOR_WIDTH, ANCHOR_HEIGHT))\n",
    "    #m = K.where((true_offset[:,:,:,0]!=0) | (true_offset[:,:,:,1]!=0))\n",
    "    #offset_mask[true_offset[:,:,:,0]!=0] = 1.0\n",
    "    #offset_mask[true_offset[:,:,:,1]!=0] = 1.0\n",
    "    \n",
    "    g_x = K.less(true_offset_x, 0)\n",
    "    l_x = K.greater(true_offset_x, 0)\n",
    "    g_y = K.greater(true_offset_y, 0)\n",
    "    l_y = K.less(true_offset_y, 0)\n",
    "    \n",
    "    g_x_i = K.cast(g_x, dtype='float32')\n",
    "    l_x_i = K.cast(l_x, dtype='float32')\n",
    "    g_y_i = K.cast(g_y, dtype='float32')\n",
    "    l_y_i = K.cast(l_y, dtype='float32')\n",
    "\n",
    "    mask_offset_x = K.clip(g_x_i + l_x_i, 0, 1.0)\n",
    "    mask_offset_y = K.clip(g_y_i + l_y_i, 0, 1.0)\n",
    "    #zeroes = K.zeros_like(true_offset_x)\n",
    "    #ones = K.ones_like(true_offset_x)\n",
    "    #mask_offset = K.where(mask_offset_bool, ones, zeroes)\n",
    "    \n",
    "    #pred_conf = K.sigmoid(c_predictions)\n",
    "    #pred_conf = c_predictions\n",
    "\n",
    "    #c_loss = K.sum(\n",
    "    #    -(c_labels * K.log(pred_conf + EPSILON) + (1-c_labels) * K.log(1-pred_conf + EPSILON))\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    c_labels * (-K.log(c_predictions + EPSILON)) + (1-c_labels) * (-K.log(1-c_predictions + EPSILON)) * c_labels\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.maximum(K.abs(c_predictions), 0) - c_predictions * c_labels + K.log(1 + K.exp(-K.abs(c_predictions)))\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.maximum(K.abs(c_predictions), 0) - c_predictions * c_labels + K.log(1 + K.exp(-K.abs(c_predictions)))\n",
    "    #, axis=0) / BATCHSIZE\n",
    "\n",
    "    #c_loss = K.sum(c_loss) / (ANCHOR_HEIGHT * ANCHOR_WIDTH)\n",
    "    \n",
    "    #diff = K.abs(c_labels - c_predictions)\n",
    "    #c_loss = 2 * (K.sigmoid(diff) - 0.5)\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.sigmoid(\n",
    "    #        K.abs(\n",
    "    #            c_labels - c_predictions\n",
    "    #        )\n",
    "    #    )\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    2 * K.sigmoid(\n",
    "    #        K.abs(\n",
    "    #            c_labels - c_predictions\n",
    "    #        )\n",
    "    #    ) - 0.5\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.abs(\n",
    "    #        c_labels - c_predictions\n",
    "    #    )\n",
    "    #)\n",
    "    \n",
    "    \n",
    "    #c_loss = K.sig\n",
    "    \n",
    "    # number of labels\n",
    "    num_labels = K.sum(c_labels)  # Accounts for batch size\n",
    "    num_non_labels = ANCHOR_WIDTH * ANCHOR_HEIGHT - num_labels\n",
    "    \n",
    "    # Loss matrix for all entries\n",
    "    loss_m_all = keras_binary_crossentropy(c_labels, c_predictions, EPSILON)\n",
    "    \n",
    "    # Loss matrix for the correct label\n",
    "    loss_m_label = keras_binary_crossentropy(c_labels, c_predictions, EPSILON) * c_labels\n",
    "    \n",
    "    # Loss matrix for non labels\n",
    "    loss_m_nonlabel = loss_m_all - loss_m_label\n",
    "    \n",
    "    # Summing and adding weight to label loss\n",
    "    c_loss_label = K.sum(\n",
    "        loss_m_label\n",
    "    ) / num_labels\n",
    "    \n",
    "    # summing and adding weight to non label loss\n",
    "    c_loss_nonlabel = K.sum(\n",
    "        loss_m_nonlabel\n",
    "    ) / num_non_labels\n",
    "    \n",
    "    c_loss = c_loss_label * LABEL_WEIGHT + c_loss_nonlabel * (1 / LABEL_WEIGHT)\n",
    "    \n",
    "    \n",
    "    o_loss_x = K.sum(\n",
    "        #K.pow(true_offset_x - pred_offset_x, 2) * mask_offset_x\n",
    "        #K.abs(true_offset_x - pred_offset_x) * mask_offset_x\n",
    "        K.square((true_offset_x - pred_offset_x) * mask_offset_x)\n",
    "    ) / num_labels\n",
    "    \n",
    "    o_loss_y = K.sum(\n",
    "        #K.pow(true_offset_y - pred_offset_y, 2) * mask_offset_y\n",
    "        #K.abs(true_offset_y - pred_offset_y) * mask_offset_y\n",
    "        K.square((true_offset_y - pred_offset_y) * mask_offset_y)\n",
    "    ) / num_labels\n",
    "    \n",
    "    o_loss = (o_loss_x + o_loss_y) * OFFSET_LOSS_WEIGHT\n",
    "    \n",
    "    # Only on correct label\n",
    "    #o_loss = K.sum(\n",
    "    #    #K.pow(pred_offset - true_offset, 2) * offset_mask\n",
    "    #    (K.pow(\n",
    "    #        true_offset[:, :, :, 0] - pred_offset[:, :, :, 0], 2\n",
    "    #    ) + K.pow(\n",
    "    #        true_offset[:, :, :, 1] - pred_offset[:, :, :, 1], 2\n",
    "    #    ))# * offset_mask\n",
    "    #) / BATCHSIZE / num_labels\n",
    "    \n",
    "    #l2_loss = K.sum(\n",
    "    #    2 * K.sigmoid (\n",
    "    #        K.sqrt(\n",
    "    #            K.pow(y_true_offset[0] - y_true_offset[0], 2) + K.pow(y_true_offset[1] - y_pred_offset[1], 2)\n",
    "    #        )\n",
    "    #    ) - 0.5\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #l2_loss = K.sum(\n",
    "    #    2 * K.sigmoid(\n",
    "    #        K.pow(y_pred_offset - y_true_offset, 2)\n",
    "    #    ) - 0.5\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    \n",
    "    #o_loss = 0\n",
    "    \n",
    "    total_loss = o_loss + c_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "#y_true_test = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "#y_pred_test = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "#l = loss(y_pred_test, y_true_test)\n",
    "#print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe643b3f278>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    sigm = 1. / (1. + np.exp(-x))\n",
    "    if derivative:\n",
    "        return sigm * (1. - sigm)\n",
    "    return sigm\n",
    "\n",
    "x = np.linspace(-10, 10, 500)\n",
    "y = np.tanh(x) # (sigmoid(x))\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$−(ylog(p)+(1−y)log(1−p))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/48951109/keras-custom-binary-cross-entropy-loss-function-get-nan-as-output-for-loss<br>\n",
    "$max(x, 0) - x * z + log(1 + exp(-abs(x)))$<br>\n",
    "$max(p, 0) - p * y + log(1 + exp(-abs(p)))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "c_labels = 1\n",
    "pred_conf = 0\n",
    "\n",
    "diff = abs(c_labels - pred_conf)\n",
    "l = (sigmoid(diff) - 0.5) * 2\n",
    "#print(l)\n",
    "\n",
    "#pred_conf = sigmoid(pred_conf)\n",
    "#ll = -(c_labels * np.log(pred_conf + EPSILON) + (1 - c_labels) * np.log(1-pred_conf + EPSILON))\n",
    "#print(ll)\n",
    "\n",
    "lll = np.max(np.abs(pred_conf), 0) - pred_conf * c_labels + np.log(1 + np.exp(-np.abs(pred_conf)))\n",
    "print(lll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 20, 20, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "y_t[:, 10, 10, 0] = 1.0\n",
    "print(y_t.shape)\n",
    "#np.max(np.maximum(-y_t, 0))\n",
    "np.sum(y_t) / BATCHSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "[[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([[1, 2, 3],\n",
    "                 [1, 2, 3],\n",
    "                 [1, 2, 3]])\n",
    "\n",
    "arr2 = np.array([[4, 5, 6],\n",
    "                 [4, 5, 6],\n",
    "                 [4, 5, 6]])\n",
    "\n",
    "res = np.concatenate((arr1, arr2), axis=-1)\n",
    "print(arr1.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label loss: 0.0\n",
      "Non label loss: 4.605170185988092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.605170185988092"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def np_loss(y_true, y_pred, bs):\n",
    "    #c_predictions = y_pred[:, :, :, 0]\n",
    "    #c_labels = y_true[:, :, :, 0]\n",
    "\n",
    "    c_predictions = y_pred\n",
    "    c_labels = y_true\n",
    "\n",
    "    \n",
    "    # number of labels\n",
    "    num_labels = np.sum(c_labels)\n",
    "    num_non_labels = 3 * 3 - num_labels   # ANCHOR_WIDTH and ANCHOR_HEIGHT\n",
    "    \n",
    "    # Loss matrix for all entries\n",
    "    loss_m_all = binary_crossentropy(c_labels, c_predictions, EPSILON)\n",
    "    \n",
    "    # Loss matrix for the correct label\n",
    "    loss_m_label = binary_crossentropy(c_labels, c_predictions, EPSILON) * c_labels\n",
    "    #print(loss_m_label)\n",
    "    \n",
    "    # Loss matrix for non labels\n",
    "    loss_m_nonlabel = loss_m_all - loss_m_label\n",
    "    #print(loss_m_nonlabel)\n",
    "    \n",
    "    # Summing and adding weight to label loss\n",
    "    c_loss_label = np.sum(\n",
    "        loss_m_label\n",
    "    ) / bs / num_labels\n",
    "    \n",
    "    # summing and adding weight to non label loss\n",
    "    c_loss_nonlabel = np.sum(\n",
    "        loss_m_nonlabel\n",
    "    ) / bs / num_non_labels\n",
    "    \n",
    "    print(f\"Label loss: {c_loss_label}\")\n",
    "    print(f\"Non label loss: {c_loss_nonlabel}\")\n",
    "    \n",
    "    c_loss = c_loss_label * LABEL_WEIGHT + c_loss_nonlabel * (1 / LABEL_WEIGHT)\n",
    "    \n",
    "    return c_loss\n",
    "\n",
    "\n",
    "#labels_test = np.copy(labels[-20:])\n",
    "#print(labels_test[:, :, :, 0].shape)\n",
    "#labels_test[:, :, :, 0] = 2\n",
    "#np_loss(labels[:20], labels_test)\n",
    "#print(np_loss(labels[-5:], labels[:5], 5))\n",
    "#print(np_loss(labels[:20], labels[:20], 20))\n",
    "\n",
    "\n",
    "true_test = np.array([[0, 0, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "pred_test = np.array([[0, 1, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "np_loss(true_test, pred_test, bs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith tf.Session() as s:\\n    # Some tensor we want to print the value of\\n    y_true_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\\n    y_pred_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\\n    s.run(tf.global_variables_initializer())\\n    \\n    l = loss(y_pred_test, y_true_test)\\n    # Add print operation\\n    print(s.run(l))\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "\n",
    "\"\"\"\n",
    "with tf.Session() as s:\n",
    "    # Some tensor we want to print the value of\n",
    "    y_true_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    y_pred_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    \n",
    "    l = loss(y_pred_test, y_true_test)\n",
    "    # Add print operation\n",
    "    print(s.run(l))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.841361487904734\n"
     ]
    }
   ],
   "source": [
    "c_labels = 0\n",
    "c_predictions = 1\n",
    "c_loss = (c_labels * (-np.log(c_predictions + EPSILON))) + (1-c_labels) * (-np.log(1-c_predictions + EPSILON))\n",
    "print(c_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Model(inputs=input_layer, outputs=preds)\n",
    "#model.compile(loss='mse', optimizer='adam')\n",
    "#model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/annot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-054207b8aa0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mlabels_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-054207b8aa0f>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/annot'"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \n",
    "    with open(annotation, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    gt = [(None, None)] * len(lines)\n",
    "    gt = np.zeros((len(lines), 2))\n",
    "    \n",
    "    for l in lines:\n",
    "        obj = l.split(',')\n",
    "        pic_id = int(obj[0].split('.')[0])\n",
    "        x = int(obj[1])\n",
    "        y = int(obj[2])\n",
    "        \n",
    "        gt[pic_id] = (x, y)\n",
    "\n",
    "    images = []\n",
    "    \n",
    "    for fi in os.listdir(DATA_DIR):\n",
    "        if not fi.endswith('jpg'):\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(DATA_DIR, fi))\n",
    "        images.append(im)\n",
    "    \n",
    "    return gt, images\n",
    "\n",
    "labels_clean, images_clean = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def closest_anchor_map(x, y, anchor_coords):\n",
    "    \"\"\" Create a anchor_height x anchor_width x 3 map.\n",
    "        First entry is 1 if the anchor point is closest to true point. Zero otherwise.\n",
    "        Second is x offset.\n",
    "        Third is y offset. \"\"\"\n",
    "    closest = 10000\n",
    "    closest_x = None\n",
    "    closest_y = None\n",
    "    closest_x_offset = None\n",
    "    closest_y_offset = None\n",
    "    \n",
    "    res = np.zeros((ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    for ix in range(ANCHOR_HEIGHT):\n",
    "        for iy in range(ANCHOR_WIDTH):\n",
    "            p_x, p_y = anchor_coords[ix, iy]\n",
    "            dist = np.sqrt( (x - p_x)**2 + (y - p_y)**2 )\n",
    "            #res[ix, iy, 1:] = (x - p_x, y - p_y)\n",
    "            if dist < closest:\n",
    "                closest = dist\n",
    "                closest_x = ix\n",
    "                closest_y = iy\n",
    "                closest_x_offset = (x - p_x)\n",
    "                closest_y_offset = (y - p_y)\n",
    "    \n",
    "    #print(f\"({closest_x}, {closest_y}) -> {anchor_coords[closest_x, closest_y]}\")\n",
    "    res[closest_x, closest_y, 0] = 1\n",
    "    res[closest_x, closest_y, 1:] = (closest_x_offset, closest_y_offset)\n",
    "    \n",
    "    return res\n",
    "        \n",
    "test_map = closest_anchor_map(20, 30, anchs)\n",
    "print(test_map.shape)\n",
    "print(np.count_nonzero(test_map[:,:, 0]))\n",
    "print(np.mean(test_map[:, :, 1]))\n",
    "print(np.mean(test_map[:, :, 2]))\n",
    "anc_indicies = np.where(test_map[:, :, 0] == test_map[:, :, 0].max())\n",
    "print(test_map[anc_indicies[0], anc_indicies[1]])\n",
    "anchor_point = test_map[anc_indicies[0], anc_indicies[1]][:,1:][0]\n",
    "print(anchs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_anchors():\n",
    "    # load images\n",
    "    # labels will be:\n",
    "    #   anchor_height x anchor_width x 3\n",
    "    #     the last 3 entries is: 1 if closest gridpoint to a point. x and y offsets to closest point.\n",
    "    with open(annotation, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    gt = np.zeros((len(lines), ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    gt_clean = [(None, None)] * len(lines)\n",
    "    images = np.zeros((len(lines), HEIGHT, WIDTH, 3))#, dtype=np.uint8)\n",
    "    \n",
    "    for c, l in enumerate(tqdm(lines)):\n",
    "        obj = l.split(',')\n",
    "        pic_id = int(obj[0].split('.')[0])\n",
    "        x = int(obj[1])\n",
    "        y = int(obj[2])\n",
    "        \n",
    "        gt[pic_id, :, :] = closest_anchor_map(x, y, anchs)\n",
    "        gt_clean[pic_id] = (x, y)\n",
    "    \n",
    "    #images = []\n",
    "    \n",
    "    for fi in tqdm(os.listdir(DATA_DIR)):\n",
    "        if not fi.endswith('jpg'):\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(DATA_DIR, fi))\n",
    "        #images.append(im)\n",
    "        i = int(fi.split('.')[0])\n",
    "        images[i] = im / 255.0\n",
    "    \n",
    "    images = np.array(images)\n",
    "    \n",
    "    return gt, gt_clean, images\n",
    "        \n",
    "labels, labels_clean, images = load_data_with_anchors()\n",
    "print(labels.shape)\n",
    "print(images[0].dtype)\n",
    "\n",
    "num_data = len(labels)\n",
    "num_validation_data = int(VALIDATION_SPLIT * num_data)\n",
    "validation_labels = labels[:num_validation_data]\n",
    "validation_images = images[:num_validation_data]\n",
    "labels = labels[num_validation_data:]\n",
    "images = images[num_validation_data:]\n",
    "\n",
    "print(len(validation_labels))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels[5][0][0])\n",
    "#np.max(images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check it everythin gets loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_points_from_prediction(pred, threshold=1.0, do_scale=True):\n",
    "    \"\"\"\n",
    "    pred is a prediction map in the shape (ANCHOR_HEIGHT, ANCHOR_WIDTH, 3)\n",
    "    \"\"\"\n",
    "    # Get all points with a confidence above threshold\n",
    "    label_indicies = np.where(pred[:, :, 0] >= threshold)\n",
    "    num_points = len(label_indicies[0])\n",
    "    #print(f\"max label index: {np.max(label_indicies)}\")\n",
    "    #print(f\"Values above threshold: {num_points}\")\n",
    "    \n",
    "    points = np.zeros((num_points, 4))#, dtype=np.int32)\n",
    "    \n",
    "    # Loop through all anchor points\n",
    "    for c, (x_anchor, y_anchor) in enumerate(zip(label_indicies[0], label_indicies[1])):\n",
    "        #print(x_anchor)\n",
    "        # when anchor location is known, the location of the closest anchor in the actual image can be found\n",
    "        x_without_offset, y_without_offset = anchs[x_anchor, y_anchor]\n",
    "        #print(f\"Anchor: ({x_anchor, y_anchor})\")\n",
    "        \n",
    "        # The offset can then be extracted from the labels\n",
    "        (x_offset, y_offset) = pred[label_indicies[0], label_indicies[1]][0][1:]\n",
    "        #print(f\"Raw offset: ({x_offset}, {y_offset})\")\n",
    "        if do_scale:\n",
    "            x_offset = 2 * (x_offset - 0.5) * OFFSET_WEIGHT\n",
    "            y_offset = 2 * (y_offset - 0.5) * OFFSET_WEIGHT\n",
    "        #print(f\"({x_offset}, {y_offset})\")\n",
    "        \n",
    "        # and the final point calculated\n",
    "        #actual_x = int(x_without_offset + x_offset)\n",
    "        #actual_y= int(y_without_offset + y_offset)\n",
    "\n",
    "        points[c] = (x_without_offset, y_without_offset, x_offset, y_offset)\n",
    "    \n",
    "    return points.astype(np.int32)\n",
    "    \n",
    "\n",
    "p = labels[0]\n",
    "#print(p.shape)\n",
    "pp = get_all_points_from_prediction(p)\n",
    "print(pp)\n",
    "print(\"\")\n",
    "pp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "im = np.copy(images[index]) * 255.0\n",
    "#im = im.astype(np.uint8)\n",
    "\n",
    "im_anchors = np.copy(images[index]) * 255.0\n",
    "#im = im.astype(np.uint8)\n",
    "\n",
    "print(anchs[1, 1])\n",
    "\n",
    "# draw all anchors\n",
    "for anc_x in range(ANCHOR_HEIGHT):\n",
    "    for anc_y in range(ANCHOR_WIDTH):\n",
    "        cv2.circle(im_anchors, (anchs[anc_x, anc_y][0], anchs[anc_x, anc_y][1]), 1, (128, 128, 128), thickness=1)\n",
    "\n",
    "\n",
    "\n",
    "# Get labels with max value, we know this to only be one in the labels\n",
    "label_indicies = np.where(labels[index, :, :, 0] == labels[index, :, :, 0].max())\n",
    "print(f\"Max values in labels: {len(label_indicies[0])}\")\n",
    "\n",
    "# Get location in the anchor\n",
    "#x_anchor, y_anchor = label_indicies\n",
    "# when anchor location is known, the location of the closest anchor in the actual image can be found\n",
    "#x_without_offset, y_without_offset = anchs[x_anchor[0], y_anchor[0]]\n",
    "\"\"\"\n",
    "# The offset can then be extracted from the labels\n",
    "(x_offset, y_offset) = labels[index, label_indicies[0], label_indicies[1]][0][1:]\n",
    "# and the final point calculated\n",
    "actual_x = int(x_without_offset + x_offset)\n",
    "actual_y= int(y_without_offset + y_offset)\n",
    "print(f\"Actual point: ({actual_x}, {actual_y})\")\n",
    "\"\"\"\n",
    "actual_x_anch, actual_y_anch, actual_x_off, actual_y_off = get_all_points_from_prediction(labels[index],\n",
    "                                                                                          do_scale=False)[0]\n",
    "actual_point = (actual_x_anch + actual_x_off, actual_y_anch + actual_y_off)\n",
    "\n",
    "cv2.circle(im, (actual_y_anch, actual_x_anch), 2, (0, 255, 0), thickness=2)\n",
    "cv2.circle(im, (actual_point[1], actual_point[0]), 2, (255, 0, 0), thickness=2)\n",
    "print(f\"Anchor: ({actual_x_anch}, {actual_y_anch})\")\n",
    "print(labels[index, label_indicies[0], label_indicies[1]])\n",
    "\n",
    "f, subs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "subs[0].imshow(im_anchors.astype(np.uint8))\n",
    "subs[0].set_title(\"Anchor points\")\n",
    "subs[1].imshow(im.astype(np.uint8))\n",
    "subs[1].set_title(\"Red is center, green is closest anchor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = np.array(labels)#.reshape(1, 100, 2)\n",
    "#print(labels.shape)\n",
    "#print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c, i in enumerate(images):\n",
    "#    model.fit(i.reshape(1, 320, 320, 3), labels[c].reshape(1, 2), epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(images.reshape(-1, 320, 320, 3), labels.reshape(-1, 2), batch_size=10, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def loss(y_true, y_pred):\n",
    "#    return K.sqrt(K.sum(K.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintInfo(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        decay = self.model.optimizer.decay\n",
    "        iterations = self.model.optimizer.iterations\n",
    "        lr_with_decay = lr / (1. + decay * K.cast(iterations, K.dtype(decay)))\n",
    "        print(f\"Learning rate with decay: {K.eval(lr_with_decay)}\")\n",
    "        #print(f\"lr={K.eval(lr)}, decay={K.eval(decay)}\")\n",
    "        print(\"\")\n",
    "        \n",
    "print_info = PrintInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=1e-4, decay=1e-4) #, clipnorm=1.0)\n",
    "#opt = optimizers.RMSprop(lr=0.001)#,  clipnorm=1.0)\n",
    "#opt = optimizers.SGD(lr=0.01, decay=0.001, momentum=0.9, nesterov=False)\n",
    "#opt = optimizers.Adagrad(lr=1e-3, decay=1e-3, clipnorm=1.0)\n",
    "#opt =optimizers.SGD()\n",
    "model.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.fit(images.reshape(-1, 320, 320, 3), labels.reshape(-1, 2), batch_size=10, epochs=10, verbose=1)\n",
    "model.fit(images.reshape(-1, 320, 320, 3),\n",
    "          labels.reshape(-1, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3),\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=1000,\n",
    "          verbose=1,\n",
    "          callbacks=[print_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_IMAGE_INDEX = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "before = time.time()\n",
    "res = model.predict(images[CHECK_IMAGE_INDEX].reshape(1, 320, 320, 3)).reshape(ANCHOR_HEIGHT, ANCHOR_WIDTH, 3)\n",
    "after = time.time()\n",
    "print(f\"Forward pass time: {after-before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indicies = np.where(res[:,:,0] == res[:,:,0].max())\n",
    "#print(indicies)\n",
    "print(f\"Max values found: {len(indicies[0])}\")\n",
    "print(res[indicies[0][0], indicies[1][0], 0])\n",
    "#print(res[indicies[0][5], indicies[1][5], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indicies = np.where(labels[CHECK_IMAGE_INDEX, :, :, 0] == labels[CHECK_IMAGE_INDEX, :, :, 0].max())\n",
    "print(f\"Max values in labels: {len(label_indicies[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of anchors: {ANCHOR_WIDTH * ANCHOR_HEIGHT}\")\n",
    "max_val = np.max(res[:, :, 0])\n",
    "print(f\"Max value: {max_val}\")\n",
    "above_val = max_val\n",
    "print(f\"Number of values above or equal to {above_val}: {np.count_nonzero(res[:, :, 0] >= above_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copy the image, so we don't change anything\n",
    "im_res = np.copy(images[CHECK_IMAGE_INDEX])\n",
    "im_res *= 255.0\n",
    "im_res = im_res.astype(np.uint8)\n",
    "\n",
    "for x_res, y_res, x_offset, y_offset in get_all_points_from_prediction(res, threshold=above_val):\n",
    "    prediction_x = x_res + x_offset\n",
    "    prediction_y = y_res + y_offset\n",
    "    cv2.circle(im_res, (prediction_y, prediction_x), 1, (0, 255, 0), thickness=3)\n",
    "    print(f\"Predicted point(green) anchor: ({x_res}, {y_res}), offset: ({x_offset}, {y_offset})\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "x_actual, y_actual, x_act_offset, y_act_offset = get_all_points_from_prediction(labels[CHECK_IMAGE_INDEX],\n",
    "                                                                                do_scale=False)[0]\n",
    "x_label_point = (x_actual + x_act_offset, y_actual + y_act_offset)\n",
    "cv2.circle(im_res, (x_label_point[1], x_label_point[0]), 1, (255, 0, 0), thickness=2)\n",
    "print(f\"Center(red) point anchor: ({x_actual}, {y_actual}), offset: ({x_act_offset}, {y_act_offset})\")\n",
    "\n",
    "f = plt.figure(figsize=(15, 8))\n",
    "plt.imshow(im_res)\n",
    "plt.title(\"Predicted in green, center in red.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_x = res[:, :, 1]\n",
    "res_y = res[:, :, 2]\n",
    "\n",
    "print(f\"Max x prediction: {np.max(res_x)}, min x prediction: {np.min(res_x)}\")\n",
    "print(f\"Max y prediction: {np.max(res_y)}, min y prediction: {np.min(res_y)}\")\n",
    "\n",
    "f, subs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "subs[0].imshow(res_x, cmap='gray')\n",
    "subs[0].set_title(\"X offset predictions\")\n",
    "subs[1].imshow(res_y, cmap='gray')\n",
    "subs[1].set_title(\"Y offset prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "print(layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_from_filterdata(filter_data):\n",
    "    if(np.min(filter_data) < 0):\n",
    "        filter_data = filter_data - np.min(filter_data)\n",
    "\n",
    "    filter_data = (filter_data - np.min(filter_data)) / (np.max(filter_data) - np.min(filter_data))\n",
    "    filter_data_gray = np.zeros((filter_data.shape[0], filter_data.shape[1]))\n",
    "    filter_data_gray = np.mean(filter_data, axis=2)\n",
    "    \n",
    "    return filter_data_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layer_name = \"conv1\"\n",
    "num_filters = 32\n",
    "\n",
    "col_plots = 4\n",
    "row_plots = int(np.ceil(num_filters / 4))\n",
    "\n",
    "f, subs = plt.subplots(row_plots, col_plots, figsize=(15, 4*row_plots))\n",
    "subs = subs.ravel()\n",
    "\n",
    "layer_output = layer_dict[layer_name].output\n",
    "\n",
    "for i in range(num_filters):\n",
    "    #filter_weights = layer_output[:, :, :, i]\n",
    "    filters = layer_dict[layer_name].get_weights()[0]\n",
    "    filter_index_data = filters[:, :, :, i]\n",
    "    filter_index_gray = get_image_from_filterdata(filter_index_data)\n",
    "\n",
    "    subs[i].imshow(filter_index_gray, cmap='gray')\n",
    "    subs[i].set_title(f\"Filter {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data, labels):\n",
    "    \n",
    "    error = 0\n",
    "    min_error = None\n",
    "    max_error = None\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        p = model.predict(data[i].reshape(1, 320, 320, 3)).reshape(ANCHOR_HEIGHT, ANCHOR_WIDTH, 3)\n",
    "        \n",
    "        # Note, only using first point\n",
    "        predicted_points = get_all_points_from_prediction(p, threshold=np.max(p[:, :, 0]))[0]\n",
    "        predicted_x = predicted_points[0] + predicted_points[2]\n",
    "        predicted_y = predicted_points[1] + predicted_points[3]\n",
    "\n",
    "        label_point = get_all_points_from_prediction(labels[i], do_scale=False)[0]\n",
    "        label_x = label_point[0] + label_point[2]\n",
    "        label_y = label_point[1] + label_point[3]\n",
    "        \n",
    "        dist = np.sqrt((predicted_x - label_x)**2 + (predicted_y - label_y)**2)\n",
    "        #print(f\"{i}: {dist}, ({label_x}, {label_y}) -> ({predicted_x}, {predicted_y})\")\n",
    "        \n",
    "        if min_error is None:\n",
    "            min_error = dist\n",
    "        else:\n",
    "            if dist < min_error:\n",
    "                min_error = dist\n",
    "                \n",
    "        if max_error is None:\n",
    "            max_error = dist\n",
    "        else:\n",
    "            if dist > max_error:\n",
    "                max_error = dist\n",
    "        \n",
    "        error += dist\n",
    "\n",
    "    error /= (i+1)\n",
    "    \n",
    "    return error, min_error, max_error\n",
    "    \n",
    "e, min_e, max_e = accuracy(validation_images, validation_labels)\n",
    "print(f\"Average error: {e}\")\n",
    "print(f\"min error: {min_e}\")\n",
    "print(f\"max error: {max_e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
