{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initially just some playing round with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Image<br>\n",
    "Initial output: center of hand<br>\n",
    "Is anchors needed? So the prediction is an offset?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SqueezeDetHelpers import fire_layer, binary_crossentropy, keras_binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grid over image size\n",
    "    - Grid nodes will be anchors\n",
    "    - Net predicts: Probability of class at anchor, and offset from anchor.\n",
    "        - In later versions, several offsets will be predicted at each offset.\n",
    "- The net is fully convolutional, meaning the output must be feature maps.\n",
    "    - Amount of output filters will then be confidence+x_offset+y_offset\n",
    "    - filter size will be the size of the anchor grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"./data\"\n",
    "ANNOTATION_FILE = r\"annot\"\n",
    "annotation = os.path.join(DATA_DIR, ANNOTATION_FILE)\n",
    "print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 320\n",
    "WIDTH = 320\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_DECAY = 0 # 0.001\n",
    "KEEP_PROB = 0.5\n",
    "CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_HEIGHT = 20\n",
    "ANCHOR_WIDTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_WEIGHT = 1.0\n",
    "OFFSET_LOSS_WEIGHT = 1.0\n",
    "OFFSET_WEIGHT = 40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_anchor_nodes = ANCHOR_HEIGHT * ANCHOR_WIDTH\n",
    "\n",
    "print(f\"Out dim: {ANCHOR_HEIGHT}x{ANCHOR_WIDTH}\")\n",
    "print(f\"Number of anchor nodes: {num_anchor_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_anchors():\n",
    "    \n",
    "    #anchors = np.zeros((num_anchor_nodes, 2))\n",
    "    anchors = np.zeros((ANCHOR_HEIGHT, ANCHOR_WIDTH, 2), dtype=np.uint32)\n",
    "    print(f\"Number of anchors: {num_anchor_nodes}\")\n",
    "    \n",
    "    print(f\"Anchor dimension: ({ANCHOR_HEIGHT}, {ANCHOR_WIDTH})\")\n",
    "    print(f\"Anchor shape: {anchors.shape}\")\n",
    "    \n",
    "    #xs = np.arange(PIXELS_BETWEEN_ANCHORS, WIDTH, PIXELS_BETWEEN_ANCHORS)\n",
    "    #ys = np.arange(PIXELS_BETWEEN_ANCHORS, HEIGHT, PIXELS_BETWEEN_ANCHORS)\n",
    "    \n",
    "    x_start = WIDTH / (ANCHOR_WIDTH + 1)\n",
    "    x_end = WIDTH - x_start\n",
    "    y_start = HEIGHT / (ANCHOR_HEIGHT + 1)\n",
    "    y_end = HEIGHT - y_start\n",
    "    xs = np.linspace(x_start, x_end, num=ANCHOR_WIDTH, dtype=np.uint32)\n",
    "    ys = np.linspace(y_start, y_end, num=ANCHOR_HEIGHT, dtype=np.uint32)\n",
    "    \n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    for cx in range(len(xs)):\n",
    "        for cy in range(len(ys)):\n",
    "            anchors[counter] = [xs[cx], ys[cy]]\n",
    "            counter += 1\n",
    "    \"\"\"\n",
    "    \n",
    "    for ix in range(ANCHOR_HEIGHT):\n",
    "        for iy in range(ANCHOR_WIDTH):\n",
    "            anchors[ix, iy] = (xs[ix], ys[iy])\n",
    "    \n",
    "    return anchors\n",
    "    \n",
    "anchs = set_anchors()\n",
    "anchs[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name=\"input\")\n",
    "print(f\"input: {input_layer.shape}\")\n",
    "\n",
    "conv1 = Conv2D(name='conv1', filters=128, kernel_size=(3, 3), strides=(2, 2), activation=None, padding=\"SAME\",\n",
    "               use_bias=False,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(input_layer)\n",
    "print(f\"conv1: {conv1.shape}\")\n",
    "\n",
    "bn = BatchNormalization(name='bn')(conv1)\n",
    "act = Activation('relu', name='act')(bn)\n",
    "\n",
    "pool1 = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='SAME', name=\"pool1\")(act)\n",
    "print(f\"pool1: {pool1.shape}\")\n",
    "\n",
    "fire1_1 = fire_layer(name=\"fire1_1\", input=pool1, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire1_1: {fire1_1.shape}\")\n",
    "\n",
    "fire1_2 = fire_layer(name=\"fire1_2\", input=fire1_1, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire1_2: {fire1_2.shape}\")\n",
    "\n",
    "#fire1_3 = fire_layer(name=\"fire1_3\", input=fire1_2, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "#print(f\"fire1_3: {fire1_3.shape}\")\n",
    "\n",
    "pool2 = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='SAME', name=\"pool2\")(fire1_2)\n",
    "print(f\"pool2: {pool2.shape}\")\n",
    "\n",
    "fire2_1 = fire_layer(name=\"fire2_1\", input=pool2, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire2_1: {fire2_1.shape}\")\n",
    "\n",
    "fire2_2 = fire_layer(name=\"fire2_2\", input=fire2_1, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire2_2: {fire2_2.shape}\")\n",
    "\n",
    "#fire2_3 = fire_layer(name=\"fire2_3\", input=fire2_2, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "#print(f\"fire2_3: {fire2_3.shape}\")\n",
    "\n",
    "pool3 = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='SAME', name=\"pool3\")(fire2_2)\n",
    "print(f\"pool3: {pool3.shape}\")\n",
    "\n",
    "fire3_1 = fire_layer(name=\"fire3_1\", input=pool3, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire3_1: {fire3_1.shape}\")\n",
    "\n",
    "fire3_2 = fire_layer(name=\"fire3_2\", input=fire3_1, s1x1=48, e1x1=192, e3x3=192, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire3_2: {fire3_2.shape}\")\n",
    "\n",
    "\"\"\"\n",
    "fire4 = fire_layer(name=\"fire4\", input=pool2, s1x1=16, e1x1=64, e3x3=64, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire4: {fire4.shape}\")\n",
    "\n",
    "fire5 = fire_layer(name=\"fire5\", input=fire4, s1x1=16, e1x1=64, e3x3=64, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire5: {fire5.shape}\")\n",
    "\n",
    "fire6 = fire_layer(name=\"fire6\", input=fire5, s1x1=16, e1x1=64, e3x3=64, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire6: {fire6.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "conv2 = Conv2D(name='conv2', filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(pool2)\n",
    "print(f\"conv2: {conv2.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "conv3 = Conv2D(name='conv3', filters=128, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(conv2)\n",
    "print(f\"conv3: {conv3.shape}\")\n",
    "\n",
    "conv4 = Conv2D(name='conv4', filters=256, kernel_size=(3, 3), strides=(2, 2), activation='relu', padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(conv3)\n",
    "print(f\"conv4: {conv4.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "preds = Conv2D(name='preds', filters=num_out, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(fire6)\n",
    "print(f\"preds: {preds.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "#drop1 = Dropout(rate=KEEP_PROB, name=\"drop1\")(fire6)\n",
    "\n",
    "pred_conf = Conv2D(name='pred_conf', filters=1, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(fire3_2)\n",
    "print(f\"pred_conf: {pred_conf.shape}\")\n",
    "\n",
    "pred_offset = Conv2D(name='pred_offset', filters=2, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(fire3_2)\n",
    "print(f\"pred_offset: {pred_offset.shape}\")\n",
    "\n",
    "#preds = Concatenate()([pred_conf, pred_offset])\n",
    "preds = concatenate([pred_conf, pred_offset])\n",
    "print(f\"preds: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross-entropy: q * -log(p) + (1-q) * -log(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    # We are predicting a batchsize x anchorwidth x anchorheight x 3 output.\n",
    "    c_predictions = y_pred[:, :, :, 0]\n",
    "    c_labels = y_true[:, :, :, 0]\n",
    "    \n",
    "    pred_offset_x = 2 * (y_pred[:, :, :, 1] - 0.5) * OFFSET_WEIGHT\n",
    "    pred_offset_y = 2 * (y_pred[:, :, :, 2] - 0.5) * OFFSET_WEIGHT\n",
    "    \n",
    "    true_offset_x = y_true[:, :, :, 1]\n",
    "    true_offset_y = y_true[:, :, :, 2]\n",
    "    \n",
    "    #offset_mask = K.copy(true_offset[:,:,:,0])\n",
    "    #offset_mask = K.abs(true_offset[:,:,:,0]) + K.abs(true_offset[:,:,:,0])\n",
    "    \n",
    "    #offset_mask[offset_mask!=0] = 1.0\n",
    "    \n",
    "    #offset_mask = K.zeros((BATCHSIZE, ANCHOR_WIDTH, ANCHOR_HEIGHT))\n",
    "    #m = K.where((true_offset[:,:,:,0]!=0) | (true_offset[:,:,:,1]!=0))\n",
    "    #offset_mask[true_offset[:,:,:,0]!=0] = 1.0\n",
    "    #offset_mask[true_offset[:,:,:,1]!=0] = 1.0\n",
    "    \n",
    "    g_x = K.less(true_offset_x, 0)\n",
    "    l_x = K.greater(true_offset_x, 0)\n",
    "    g_y = K.greater(true_offset_y, 0)\n",
    "    l_y = K.less(true_offset_y, 0)\n",
    "    \n",
    "    g_x_i = K.cast(g_x, dtype='float32')\n",
    "    l_x_i = K.cast(l_x, dtype='float32')\n",
    "    g_y_i = K.cast(g_y, dtype='float32')\n",
    "    l_y_i = K.cast(l_y, dtype='float32')\n",
    "\n",
    "    mask_offset_x = K.clip(g_x_i + l_x_i, 0, 1.0)\n",
    "    mask_offset_y = K.clip(g_y_i + l_y_i, 0, 1.0)\n",
    "    #zeroes = K.zeros_like(true_offset_x)\n",
    "    #ones = K.ones_like(true_offset_x)\n",
    "    #mask_offset = K.where(mask_offset_bool, ones, zeroes)\n",
    "    \n",
    "    #pred_conf = K.sigmoid(c_predictions)\n",
    "    #pred_conf = c_predictions\n",
    "\n",
    "    #c_loss = K.sum(\n",
    "    #    -(c_labels * K.log(pred_conf + EPSILON) + (1-c_labels) * K.log(1-pred_conf + EPSILON))\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    c_labels * (-K.log(c_predictions + EPSILON)) + (1-c_labels) * (-K.log(1-c_predictions + EPSILON)) * c_labels\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.maximum(K.abs(c_predictions), 0) - c_predictions * c_labels + K.log(1 + K.exp(-K.abs(c_predictions)))\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.maximum(K.abs(c_predictions), 0) - c_predictions * c_labels + K.log(1 + K.exp(-K.abs(c_predictions)))\n",
    "    #, axis=0) / BATCHSIZE\n",
    "\n",
    "    #c_loss = K.sum(c_loss) / (ANCHOR_HEIGHT * ANCHOR_WIDTH)\n",
    "    \n",
    "    #diff = K.abs(c_labels - c_predictions)\n",
    "    #c_loss = 2 * (K.sigmoid(diff) - 0.5)\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.sigmoid(\n",
    "    #        K.abs(\n",
    "    #            c_labels - c_predictions\n",
    "    #        )\n",
    "    #    )\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    2 * K.sigmoid(\n",
    "    #        K.abs(\n",
    "    #            c_labels - c_predictions\n",
    "    #        )\n",
    "    #    ) - 0.5\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #c_loss = K.sum(\n",
    "    #    K.abs(\n",
    "    #        c_labels - c_predictions\n",
    "    #    )\n",
    "    #)\n",
    "    \n",
    "    \n",
    "    #c_loss = K.sig\n",
    "    \n",
    "    # number of labels\n",
    "    num_labels = K.sum(c_labels)  # Accounts for batch size\n",
    "    num_non_labels = ANCHOR_WIDTH * ANCHOR_HEIGHT - num_labels\n",
    "    \n",
    "    # Loss matrix for all entries\n",
    "    loss_m_all = keras_binary_crossentropy(c_labels, c_predictions, EPSILON)\n",
    "    \n",
    "    # Loss matrix for the correct label\n",
    "    loss_m_label = keras_binary_crossentropy(c_labels, c_predictions, EPSILON) * c_labels\n",
    "    \n",
    "    # Loss matrix for non labels\n",
    "    loss_m_nonlabel = loss_m_all - loss_m_label\n",
    "    \n",
    "    # Summing and adding weight to label loss\n",
    "    c_loss_label = K.sum(\n",
    "        loss_m_label\n",
    "    ) / num_labels\n",
    "    \n",
    "    # summing and adding weight to non label loss\n",
    "    c_loss_nonlabel = K.sum(\n",
    "        loss_m_nonlabel\n",
    "    ) / num_non_labels\n",
    "    \n",
    "    c_loss = c_loss_label * LABEL_WEIGHT + c_loss_nonlabel * (1 / LABEL_WEIGHT)\n",
    "    \n",
    "    \n",
    "    o_loss_x = K.sum(\n",
    "        #K.pow(true_offset_x - pred_offset_x, 2) * mask_offset_x\n",
    "        #K.abs(true_offset_x - pred_offset_x) * mask_offset_x\n",
    "        K.square((true_offset_x - pred_offset_x) * mask_offset_x)\n",
    "    ) / num_labels\n",
    "    \n",
    "    o_loss_y = K.sum(\n",
    "        #K.pow(true_offset_y - pred_offset_y, 2) * mask_offset_y\n",
    "        #K.abs(true_offset_y - pred_offset_y) * mask_offset_y\n",
    "        K.square((true_offset_y - pred_offset_y) * mask_offset_y)\n",
    "    ) / num_labels\n",
    "    \n",
    "    o_loss = (o_loss_x + o_loss_y) * OFFSET_LOSS_WEIGHT\n",
    "    \n",
    "    # Only on correct label\n",
    "    #o_loss = K.sum(\n",
    "    #    #K.pow(pred_offset - true_offset, 2) * offset_mask\n",
    "    #    (K.pow(\n",
    "    #        true_offset[:, :, :, 0] - pred_offset[:, :, :, 0], 2\n",
    "    #    ) + K.pow(\n",
    "    #        true_offset[:, :, :, 1] - pred_offset[:, :, :, 1], 2\n",
    "    #    ))# * offset_mask\n",
    "    #) / BATCHSIZE / num_labels\n",
    "    \n",
    "    #l2_loss = K.sum(\n",
    "    #    2 * K.sigmoid (\n",
    "    #        K.sqrt(\n",
    "    #            K.pow(y_true_offset[0] - y_true_offset[0], 2) + K.pow(y_true_offset[1] - y_pred_offset[1], 2)\n",
    "    #        )\n",
    "    #    ) - 0.5\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    #l2_loss = K.sum(\n",
    "    #    2 * K.sigmoid(\n",
    "    #        K.pow(y_pred_offset - y_true_offset, 2)\n",
    "    #    ) - 0.5\n",
    "    #) / BATCHSIZE\n",
    "    \n",
    "    \n",
    "    #o_loss = 0\n",
    "    \n",
    "    total_loss = o_loss + c_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "#y_true_test = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "#y_pred_test = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "#l = loss(y_pred_test, y_true_test)\n",
    "#print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f1c7209add8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    sigm = 1. / (1. + np.exp(-x))\n",
    "    if derivative:\n",
    "        return sigm * (1. - sigm)\n",
    "    return sigm\n",
    "\n",
    "x = np.linspace(-10, 10, 500)\n",
    "y = 2 * (sigmoid(x) - 0.5)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$−(ylog(p)+(1−y)log(1−p))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/48951109/keras-custom-binary-cross-entropy-loss-function-get-nan-as-output-for-loss<br>\n",
    "$max(x, 0) - x * z + log(1 + exp(-abs(x)))$<br>\n",
    "$max(p, 0) - p * y + log(1 + exp(-abs(p)))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_labels = 1\n",
    "pred_conf = 0\n",
    "\n",
    "diff = abs(c_labels - pred_conf)\n",
    "l = (sigmoid(diff) - 0.5) * 2\n",
    "#print(l)\n",
    "\n",
    "#pred_conf = sigmoid(pred_conf)\n",
    "#ll = -(c_labels * np.log(pred_conf + EPSILON) + (1 - c_labels) * np.log(1-pred_conf + EPSILON))\n",
    "#print(ll)\n",
    "\n",
    "lll = np.max(np.abs(pred_conf), 0) - pred_conf * c_labels + np.log(1 + np.exp(-np.abs(pred_conf)))\n",
    "print(lll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "y_t[:, 10, 10, 0] = 1.0\n",
    "print(y_t.shape)\n",
    "#np.max(np.maximum(-y_t, 0))\n",
    "np.sum(y_t) / BATCHSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([[1, 2, 3],\n",
    "                 [1, 2, 3],\n",
    "                 [1, 2, 3]])\n",
    "\n",
    "arr2 = np.array([[4, 5, 6],\n",
    "                 [4, 5, 6],\n",
    "                 [4, 5, 6]])\n",
    "\n",
    "res = np.concatenate((arr1, arr2), axis=-1)\n",
    "print(arr1.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_loss(y_true, y_pred, bs):\n",
    "    #c_predictions = y_pred[:, :, :, 0]\n",
    "    #c_labels = y_true[:, :, :, 0]\n",
    "\n",
    "    c_predictions = y_pred\n",
    "    c_labels = y_true\n",
    "\n",
    "    \n",
    "    # number of labels\n",
    "    num_labels = np.sum(c_labels)\n",
    "    num_non_labels = 3 * 3 - num_labels   # ANCHOR_WIDTH and ANCHOR_HEIGHT\n",
    "    \n",
    "    # Loss matrix for all entries\n",
    "    loss_m_all = binary_crossentropy(c_labels, c_predictions, EPSILON)\n",
    "    \n",
    "    # Loss matrix for the correct label\n",
    "    loss_m_label = binary_crossentropy(c_labels, c_predictions, EPSILON) * c_labels\n",
    "    #print(loss_m_label)\n",
    "    \n",
    "    # Loss matrix for non labels\n",
    "    loss_m_nonlabel = loss_m_all - loss_m_label\n",
    "    #print(loss_m_nonlabel)\n",
    "    \n",
    "    # Summing and adding weight to label loss\n",
    "    c_loss_label = np.sum(\n",
    "        loss_m_label\n",
    "    ) / bs / num_labels\n",
    "    \n",
    "    # summing and adding weight to non label loss\n",
    "    c_loss_nonlabel = np.sum(\n",
    "        loss_m_nonlabel\n",
    "    ) / bs / num_non_labels\n",
    "    \n",
    "    print(f\"Label loss: {c_loss_label}\")\n",
    "    print(f\"Non label loss: {c_loss_nonlabel}\")\n",
    "    \n",
    "    c_loss = c_loss_label * LABEL_WEIGHT + c_loss_nonlabel * (1 / LABEL_WEIGHT)\n",
    "    \n",
    "    return c_loss\n",
    "\n",
    "\n",
    "#labels_test = np.copy(labels[-20:])\n",
    "#print(labels_test[:, :, :, 0].shape)\n",
    "#labels_test[:, :, :, 0] = 2\n",
    "#np_loss(labels[:20], labels_test)\n",
    "#print(np_loss(labels[-5:], labels[:5], 5))\n",
    "#print(np_loss(labels[:20], labels[:20], 20))\n",
    "\n",
    "\n",
    "true_test = np.array([[0, 0, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "pred_test = np.array([[0, 1, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "np_loss(true_test, pred_test, bs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "\n",
    "\"\"\"\n",
    "with tf.Session() as s:\n",
    "    # Some tensor we want to print the value of\n",
    "    y_true_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    y_pred_test = tf.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    \n",
    "    l = loss(y_pred_test, y_true_test)\n",
    "    # Add print operation\n",
    "    print(s.run(l))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_labels = 0\n",
    "c_predictions = 1\n",
    "c_loss = (c_labels * (-np.log(c_predictions + EPSILON))) + (1-c_labels) * (-np.log(1-c_predictions + EPSILON))\n",
    "print(c_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Model(inputs=input_layer, outputs=preds)\n",
    "#model.compile(loss='mse', optimizer='adam')\n",
    "#model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    with open(annotation, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    gt = [(None, None)] * len(lines)\n",
    "    gt = np.zeros((len(lines), 2))\n",
    "    \n",
    "    for l in lines:\n",
    "        obj = l.split(',')\n",
    "        pic_id = int(obj[0].split('.')[0])\n",
    "        x = int(obj[1])\n",
    "        y = int(obj[2])\n",
    "        \n",
    "        gt[pic_id] = (x, y)\n",
    "\n",
    "    images = []\n",
    "    \n",
    "    for fi in os.listdir(DATA_DIR):\n",
    "        if not fi.endswith('jpg'):\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(DATA_DIR, fi))\n",
    "        images.append(im)\n",
    "    \n",
    "    return gt, images\n",
    "\n",
    "labels_clean, images_clean = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def closest_anchor_map(x, y, anchor_coords):\n",
    "    \"\"\" Create a anchor_height x anchor_width x 3 map.\n",
    "        First entry is 1 if the anchor point is closest to true point. Zero otherwise.\n",
    "        Second is x offset.\n",
    "        Third is y offset. \"\"\"\n",
    "    closest = 10000\n",
    "    closest_x = None\n",
    "    closest_y = None\n",
    "    closest_x_offset = None\n",
    "    closest_y_offset = None\n",
    "    \n",
    "    res = np.zeros((ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    for ix in range(ANCHOR_HEIGHT):\n",
    "        for iy in range(ANCHOR_WIDTH):\n",
    "            p_x, p_y = anchor_coords[ix, iy]\n",
    "            dist = np.sqrt( (x - p_x)**2 + (y - p_y)**2 )\n",
    "            #res[ix, iy, 1:] = (x - p_x, y - p_y)\n",
    "            if dist < closest:\n",
    "                closest = dist\n",
    "                closest_x = ix\n",
    "                closest_y = iy\n",
    "                closest_x_offset = (x - p_x)\n",
    "                closest_y_offset = (y - p_y)\n",
    "    \n",
    "    #print(f\"({closest_x}, {closest_y}) -> {anchor_coords[closest_x, closest_y]}\")\n",
    "    res[closest_x, closest_y, 0] = 1\n",
    "    res[closest_x, closest_y, 1:] = (closest_x_offset, closest_y_offset)\n",
    "    \n",
    "    return res\n",
    "        \n",
    "test_map = closest_anchor_map(20, 30, anchs)\n",
    "print(test_map.shape)\n",
    "print(np.count_nonzero(test_map[:,:, 0]))\n",
    "print(np.mean(test_map[:, :, 1]))\n",
    "print(np.mean(test_map[:, :, 2]))\n",
    "anc_indicies = np.where(test_map[:, :, 0] == test_map[:, :, 0].max())\n",
    "print(test_map[anc_indicies[0], anc_indicies[1]])\n",
    "anchor_point = test_map[anc_indicies[0], anc_indicies[1]][:,1:][0]\n",
    "print(anchs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_anchors():\n",
    "    # load images\n",
    "    # labels will be:\n",
    "    #   anchor_height x anchor_width x 3\n",
    "    #     the last 3 entries is: 1 if closest gridpoint to a point. x and y offsets to closest point.\n",
    "    with open(annotation, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    gt = np.zeros((len(lines), ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    gt_clean = [(None, None)] * len(lines)\n",
    "    images = np.zeros((len(lines), HEIGHT, WIDTH, 3))#, dtype=np.uint8)\n",
    "    \n",
    "    for c, l in enumerate(tqdm(lines)):\n",
    "        obj = l.split(',')\n",
    "        pic_id = int(obj[0].split('.')[0])\n",
    "        x = int(obj[1])\n",
    "        y = int(obj[2])\n",
    "        \n",
    "        gt[pic_id, :, :] = closest_anchor_map(x, y, anchs)\n",
    "        gt_clean[pic_id] = (x, y)\n",
    "    \n",
    "    #images = []\n",
    "    \n",
    "    for fi in tqdm(os.listdir(DATA_DIR)):\n",
    "        if not fi.endswith('jpg'):\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(DATA_DIR, fi))\n",
    "        #images.append(im)\n",
    "        i = int(fi.split('.')[0])\n",
    "        images[i] = im / 255.0\n",
    "    \n",
    "    images = np.array(images)\n",
    "    \n",
    "    return gt, gt_clean, images\n",
    "        \n",
    "labels, labels_clean, images = load_data_with_anchors()\n",
    "print(labels.shape)\n",
    "print(images[0].dtype)\n",
    "\n",
    "num_data = len(labels)\n",
    "num_validation_data = int(VALIDATION_SPLIT * num_data)\n",
    "validation_labels = labels[:num_validation_data]\n",
    "validation_images = images[:num_validation_data]\n",
    "labels = labels[num_validation_data:]\n",
    "images = images[num_validation_data:]\n",
    "\n",
    "print(len(validation_labels))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels[5][0][0])\n",
    "#np.max(images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check it everythin gets loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_points_from_prediction(pred, threshold=1.0, do_scale=True):\n",
    "    \"\"\"\n",
    "    pred is a prediction map in the shape (ANCHOR_HEIGHT, ANCHOR_WIDTH, 3)\n",
    "    \"\"\"\n",
    "    # Get all points with a confidence above threshold\n",
    "    label_indicies = np.where(pred[:, :, 0] >= threshold)\n",
    "    num_points = len(label_indicies[0])\n",
    "    #print(f\"max label index: {np.max(label_indicies)}\")\n",
    "    #print(f\"Values above threshold: {num_points}\")\n",
    "    \n",
    "    points = np.zeros((num_points, 4))#, dtype=np.int32)\n",
    "    \n",
    "    # Loop through all anchor points\n",
    "    for c, (x_anchor, y_anchor) in enumerate(zip(label_indicies[0], label_indicies[1])):\n",
    "        #print(x_anchor)\n",
    "        # when anchor location is known, the location of the closest anchor in the actual image can be found\n",
    "        x_without_offset, y_without_offset = anchs[x_anchor, y_anchor]\n",
    "        #print(f\"Anchor: ({x_anchor, y_anchor})\")\n",
    "        \n",
    "        # The offset can then be extracted from the labels\n",
    "        (x_offset, y_offset) = pred[label_indicies[0], label_indicies[1]][0][1:]\n",
    "        #print(f\"Raw offset: ({x_offset}, {y_offset})\")\n",
    "        if do_scale:\n",
    "            x_offset = 2 * (x_offset - 0.5) * OFFSET_WEIGHT\n",
    "            y_offset = 2 * (y_offset - 0.5) * OFFSET_WEIGHT\n",
    "        #print(f\"({x_offset}, {y_offset})\")\n",
    "        \n",
    "        # and the final point calculated\n",
    "        #actual_x = int(x_without_offset + x_offset)\n",
    "        #actual_y= int(y_without_offset + y_offset)\n",
    "\n",
    "        points[c] = (x_without_offset, y_without_offset, x_offset, y_offset)\n",
    "    \n",
    "    return points.astype(np.int32)\n",
    "    \n",
    "\n",
    "p = labels[0]\n",
    "#print(p.shape)\n",
    "pp = get_all_points_from_prediction(p)\n",
    "print(pp)\n",
    "print(\"\")\n",
    "pp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "im = np.copy(images[index]) * 255.0\n",
    "#im = im.astype(np.uint8)\n",
    "\n",
    "im_anchors = np.copy(images[index]) * 255.0\n",
    "#im = im.astype(np.uint8)\n",
    "\n",
    "print(anchs[1, 1])\n",
    "\n",
    "# draw all anchors\n",
    "for anc_x in range(ANCHOR_HEIGHT):\n",
    "    for anc_y in range(ANCHOR_WIDTH):\n",
    "        cv2.circle(im_anchors, (anchs[anc_x, anc_y][0], anchs[anc_x, anc_y][1]), 1, (128, 128, 128), thickness=1)\n",
    "\n",
    "\n",
    "\n",
    "# Get labels with max value, we know this to only be one in the labels\n",
    "label_indicies = np.where(labels[index, :, :, 0] == labels[index, :, :, 0].max())\n",
    "print(f\"Max values in labels: {len(label_indicies[0])}\")\n",
    "\n",
    "# Get location in the anchor\n",
    "#x_anchor, y_anchor = label_indicies\n",
    "# when anchor location is known, the location of the closest anchor in the actual image can be found\n",
    "#x_without_offset, y_without_offset = anchs[x_anchor[0], y_anchor[0]]\n",
    "\"\"\"\n",
    "# The offset can then be extracted from the labels\n",
    "(x_offset, y_offset) = labels[index, label_indicies[0], label_indicies[1]][0][1:]\n",
    "# and the final point calculated\n",
    "actual_x = int(x_without_offset + x_offset)\n",
    "actual_y= int(y_without_offset + y_offset)\n",
    "print(f\"Actual point: ({actual_x}, {actual_y})\")\n",
    "\"\"\"\n",
    "actual_x_anch, actual_y_anch, actual_x_off, actual_y_off = get_all_points_from_prediction(labels[index],\n",
    "                                                                                          do_scale=False)[0]\n",
    "actual_point = (actual_x_anch + actual_x_off, actual_y_anch + actual_y_off)\n",
    "\n",
    "cv2.circle(im, (actual_y_anch, actual_x_anch), 2, (0, 255, 0), thickness=2)\n",
    "cv2.circle(im, (actual_point[1], actual_point[0]), 2, (255, 0, 0), thickness=2)\n",
    "print(f\"Anchor: ({actual_x_anch}, {actual_y_anch})\")\n",
    "print(labels[index, label_indicies[0], label_indicies[1]])\n",
    "\n",
    "f, subs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "subs[0].imshow(im_anchors.astype(np.uint8))\n",
    "subs[0].set_title(\"Anchor points\")\n",
    "subs[1].imshow(im.astype(np.uint8))\n",
    "subs[1].set_title(\"Red is center, green is closest anchor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = np.array(labels)#.reshape(1, 100, 2)\n",
    "#print(labels.shape)\n",
    "#print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c, i in enumerate(images):\n",
    "#    model.fit(i.reshape(1, 320, 320, 3), labels[c].reshape(1, 2), epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(images.reshape(-1, 320, 320, 3), labels.reshape(-1, 2), batch_size=10, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def loss(y_true, y_pred):\n",
    "#    return K.sqrt(K.sum(K.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintInfo(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        decay = self.model.optimizer.decay\n",
    "        iterations = self.model.optimizer.iterations\n",
    "        lr_with_decay = lr / (1. + decay * K.cast(iterations, K.dtype(decay)))\n",
    "        print(f\"Learning rate with decay: {K.eval(lr_with_decay)}\")\n",
    "        #print(f\"lr={K.eval(lr)}, decay={K.eval(decay)}\")\n",
    "        print(\"\")\n",
    "        \n",
    "print_info = PrintInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=1e-4, decay=1e-4) #, clipnorm=1.0)\n",
    "#opt = optimizers.RMSprop(lr=0.001)#,  clipnorm=1.0)\n",
    "#opt = optimizers.SGD(lr=0.01, decay=0.001, momentum=0.9, nesterov=False)\n",
    "#opt = optimizers.Adagrad(lr=1e-3, decay=1e-3, clipnorm=1.0)\n",
    "#opt =optimizers.SGD()\n",
    "model.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.fit(images.reshape(-1, 320, 320, 3), labels.reshape(-1, 2), batch_size=10, epochs=10, verbose=1)\n",
    "model.fit(images.reshape(-1, 320, 320, 3),\n",
    "          labels.reshape(-1, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3),\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=1000,\n",
    "          verbose=1,\n",
    "          callbacks=[print_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_IMAGE_INDEX = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "before = time.time()\n",
    "res = model.predict(images[CHECK_IMAGE_INDEX].reshape(1, 320, 320, 3)).reshape(ANCHOR_HEIGHT, ANCHOR_WIDTH, 3)\n",
    "after = time.time()\n",
    "print(f\"Forward pass time: {after-before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indicies = np.where(res[:,:,0] == res[:,:,0].max())\n",
    "#print(indicies)\n",
    "print(f\"Max values found: {len(indicies[0])}\")\n",
    "print(res[indicies[0][0], indicies[1][0], 0])\n",
    "#print(res[indicies[0][5], indicies[1][5], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indicies = np.where(labels[CHECK_IMAGE_INDEX, :, :, 0] == labels[CHECK_IMAGE_INDEX, :, :, 0].max())\n",
    "print(f\"Max values in labels: {len(label_indicies[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of anchors: {ANCHOR_WIDTH * ANCHOR_HEIGHT}\")\n",
    "max_val = np.max(res[:, :, 0])\n",
    "print(f\"Max value: {max_val}\")\n",
    "above_val = max_val\n",
    "print(f\"Number of values above or equal to {above_val}: {np.count_nonzero(res[:, :, 0] >= above_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copy the image, so we don't change anything\n",
    "im_res = np.copy(images[CHECK_IMAGE_INDEX])\n",
    "im_res *= 255.0\n",
    "im_res = im_res.astype(np.uint8)\n",
    "\n",
    "for x_res, y_res, x_offset, y_offset in get_all_points_from_prediction(res, threshold=above_val):\n",
    "    prediction_x = x_res + x_offset\n",
    "    prediction_y = y_res + y_offset\n",
    "    cv2.circle(im_res, (prediction_y, prediction_x), 1, (0, 255, 0), thickness=3)\n",
    "    print(f\"Predicted point(green) anchor: ({x_res}, {y_res}), offset: ({x_offset}, {y_offset})\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "x_actual, y_actual, x_act_offset, y_act_offset = get_all_points_from_prediction(labels[CHECK_IMAGE_INDEX],\n",
    "                                                                                do_scale=False)[0]\n",
    "x_label_point = (x_actual + x_act_offset, y_actual + y_act_offset)\n",
    "cv2.circle(im_res, (x_label_point[1], x_label_point[0]), 1, (255, 0, 0), thickness=2)\n",
    "print(f\"Center(red) point anchor: ({x_actual}, {y_actual}), offset: ({x_act_offset}, {y_act_offset})\")\n",
    "\n",
    "f = plt.figure(figsize=(15, 8))\n",
    "plt.imshow(im_res)\n",
    "plt.title(\"Predicted in green, center in red.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_x = res[:, :, 1]\n",
    "res_y = res[:, :, 2]\n",
    "\n",
    "print(f\"Max x prediction: {np.max(res_x)}, min x prediction: {np.min(res_x)}\")\n",
    "print(f\"Max y prediction: {np.max(res_y)}, min y prediction: {np.min(res_y)}\")\n",
    "\n",
    "f, subs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "subs[0].imshow(res_x, cmap='gray')\n",
    "subs[0].set_title(\"X offset predictions\")\n",
    "subs[1].imshow(res_y, cmap='gray')\n",
    "subs[1].set_title(\"Y offset prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "print(layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_from_filterdata(filter_data):\n",
    "    if(np.min(filter_data) < 0):\n",
    "        filter_data = filter_data - np.min(filter_data)\n",
    "\n",
    "    filter_data = (filter_data - np.min(filter_data)) / (np.max(filter_data) - np.min(filter_data))\n",
    "    filter_data_gray = np.zeros((filter_data.shape[0], filter_data.shape[1]))\n",
    "    filter_data_gray = np.mean(filter_data, axis=2)\n",
    "    \n",
    "    return filter_data_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layer_name = \"conv1\"\n",
    "num_filters = 32\n",
    "\n",
    "col_plots = 4\n",
    "row_plots = int(np.ceil(num_filters / 4))\n",
    "\n",
    "f, subs = plt.subplots(row_plots, col_plots, figsize=(15, 4*row_plots))\n",
    "subs = subs.ravel()\n",
    "\n",
    "layer_output = layer_dict[layer_name].output\n",
    "\n",
    "for i in range(num_filters):\n",
    "    #filter_weights = layer_output[:, :, :, i]\n",
    "    filters = layer_dict[layer_name].get_weights()[0]\n",
    "    filter_index_data = filters[:, :, :, i]\n",
    "    filter_index_gray = get_image_from_filterdata(filter_index_data)\n",
    "\n",
    "    subs[i].imshow(filter_index_gray, cmap='gray')\n",
    "    subs[i].set_title(f\"Filter {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data, labels):\n",
    "    \n",
    "    error = 0\n",
    "    min_error = None\n",
    "    max_error = None\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        p = model.predict(data[i].reshape(1, 320, 320, 3)).reshape(ANCHOR_HEIGHT, ANCHOR_WIDTH, 3)\n",
    "        \n",
    "        # Note, only using first point\n",
    "        predicted_points = get_all_points_from_prediction(p, threshold=np.max(p[:, :, 0]))[0]\n",
    "        predicted_x = predicted_points[0] + predicted_points[2]\n",
    "        predicted_y = predicted_points[1] + predicted_points[3]\n",
    "\n",
    "        label_point = get_all_points_from_prediction(labels[i], do_scale=False)[0]\n",
    "        label_x = label_point[0] + label_point[2]\n",
    "        label_y = label_point[1] + label_point[3]\n",
    "        \n",
    "        dist = np.sqrt((predicted_x - label_x)**2 + (predicted_y - label_y)**2)\n",
    "        #print(f\"{i}: {dist}, ({label_x}, {label_y}) -> ({predicted_x}, {predicted_y})\")\n",
    "        \n",
    "        if min_error is None:\n",
    "            min_error = dist\n",
    "        else:\n",
    "            if dist < min_error:\n",
    "                min_error = dist\n",
    "                \n",
    "        if max_error is None:\n",
    "            max_error = dist\n",
    "        else:\n",
    "            if dist > max_error:\n",
    "                max_error = dist\n",
    "        \n",
    "        error += dist\n",
    "\n",
    "    error /= (i+1)\n",
    "    \n",
    "    return error, min_error, max_error\n",
    "    \n",
    "e, min_e, max_e = accuracy(validation_images, validation_labels)\n",
    "print(f\"Average error: {e}\")\n",
    "print(f\"min error: {min_e}\")\n",
    "print(f\"max error: {max_e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
