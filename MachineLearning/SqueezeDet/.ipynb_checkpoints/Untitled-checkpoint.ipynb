{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.PoolingAndFire import create_model, create_loss_function\n",
    "from PreProcess import data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 16\n",
    "EPSILON = 1e-16\n",
    "\n",
    "WEIGHT_DECAY = 0 # 0.001\n",
    "KEEP_PROB = 0.5\n",
    "CLASSES = 1\n",
    "\n",
    "LABEL_WEIGHT = 1.0\n",
    "OFFSET_LOSS_WEIGHT = 1.0\n",
    "OFFSET_WEIGHT = 40.0\n",
    "\n",
    "HEIGHT = 320\n",
    "WIDTH = 320\n",
    "CHANNELS = 3\n",
    "\n",
    "VALIDATION_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed anchor shape: 20x20\n"
     ]
    }
   ],
   "source": [
    "model = create_model(320, 320, 3)\n",
    "out_shape = model.output_shape\n",
    "anchor_width = out_shape[1]\n",
    "anchor_height = out_shape[2]\n",
    "print(f\"Needed anchor shape: {anchor_width}x{anchor_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 320, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 160, 160, 128 3456        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 160, 160, 128 512         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "act (Activation)                (None, 160, 160, 128 0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 80, 80, 128)  0           act[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/squeeze1x1 (Conv2D)     (None, 80, 80, 32)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/bn1 (BatchNormalization (None, 80, 80, 32)   128         fire1_1/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/act1 (Activation)       (None, 80, 80, 32)   0           fire1_1/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/expand1x1 (Conv2D)      (None, 80, 80, 128)  4096        fire1_1/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/bn2 (BatchNormalization (None, 80, 80, 128)  512         fire1_1/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/act2 (Activation)       (None, 80, 80, 128)  0           fire1_1/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/expand3x3 (Conv2D)      (None, 80, 80, 128)  147456      fire1_1/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/bn3 (BatchNormalization (None, 80, 80, 128)  512         fire1_1/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire1_1/act3 (Activation)       (None, 80, 80, 128)  0           fire1_1/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80, 80, 256)  0           fire1_1/act2[0][0]               \n",
      "                                                                 fire1_1/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/squeeze1x1 (Conv2D)     (None, 80, 80, 32)   8192        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/bn1 (BatchNormalization (None, 80, 80, 32)   128         fire1_2/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/act1 (Activation)       (None, 80, 80, 32)   0           fire1_2/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/expand1x1 (Conv2D)      (None, 80, 80, 128)  4096        fire1_2/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/bn2 (BatchNormalization (None, 80, 80, 128)  512         fire1_2/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/act2 (Activation)       (None, 80, 80, 128)  0           fire1_2/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/expand3x3 (Conv2D)      (None, 80, 80, 128)  147456      fire1_2/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/bn3 (BatchNormalization (None, 80, 80, 128)  512         fire1_2/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire1_2/act3 (Activation)       (None, 80, 80, 128)  0           fire1_2/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 80, 80, 256)  0           fire1_2/act2[0][0]               \n",
      "                                                                 fire1_2/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 40, 40, 256)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/squeeze1x1 (Conv2D)     (None, 40, 40, 48)   12288       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/bn1 (BatchNormalization (None, 40, 40, 48)   192         fire2_1/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/act1 (Activation)       (None, 40, 40, 48)   0           fire2_1/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/expand1x1 (Conv2D)      (None, 40, 40, 192)  9216        fire2_1/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/bn2 (BatchNormalization (None, 40, 40, 192)  768         fire2_1/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/act2 (Activation)       (None, 40, 40, 192)  0           fire2_1/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/expand3x3 (Conv2D)      (None, 40, 40, 192)  331776      fire2_1/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/bn3 (BatchNormalization (None, 40, 40, 192)  768         fire2_1/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire2_1/act3 (Activation)       (None, 40, 40, 192)  0           fire2_1/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 40, 40, 384)  0           fire2_1/act2[0][0]               \n",
      "                                                                 fire2_1/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/squeeze1x1 (Conv2D)     (None, 40, 40, 48)   18432       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/bn1 (BatchNormalization (None, 40, 40, 48)   192         fire2_2/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/act1 (Activation)       (None, 40, 40, 48)   0           fire2_2/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/expand1x1 (Conv2D)      (None, 40, 40, 192)  9216        fire2_2/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/bn2 (BatchNormalization (None, 40, 40, 192)  768         fire2_2/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/act2 (Activation)       (None, 40, 40, 192)  0           fire2_2/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/expand3x3 (Conv2D)      (None, 40, 40, 192)  331776      fire2_2/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/bn3 (BatchNormalization (None, 40, 40, 192)  768         fire2_2/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire2_2/act3 (Activation)       (None, 40, 40, 192)  0           fire2_2/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 40, 40, 384)  0           fire2_2/act2[0][0]               \n",
      "                                                                 fire2_2/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 20, 20, 384)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/squeeze1x1 (Conv2D)     (None, 20, 20, 48)   18432       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/bn1 (BatchNormalization (None, 20, 20, 48)   192         fire3_1/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/act1 (Activation)       (None, 20, 20, 48)   0           fire3_1/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/expand1x1 (Conv2D)      (None, 20, 20, 192)  9216        fire3_1/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/bn2 (BatchNormalization (None, 20, 20, 192)  768         fire3_1/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/act2 (Activation)       (None, 20, 20, 192)  0           fire3_1/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/expand3x3 (Conv2D)      (None, 20, 20, 192)  331776      fire3_1/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/bn3 (BatchNormalization (None, 20, 20, 192)  768         fire3_1/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire3_1/act3 (Activation)       (None, 20, 20, 192)  0           fire3_1/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 20, 20, 384)  0           fire3_1/act2[0][0]               \n",
      "                                                                 fire3_1/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/squeeze1x1 (Conv2D)     (None, 20, 20, 48)   18432       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/bn1 (BatchNormalization (None, 20, 20, 48)   192         fire3_2/squeeze1x1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/act1 (Activation)       (None, 20, 20, 48)   0           fire3_2/bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/expand1x1 (Conv2D)      (None, 20, 20, 192)  9216        fire3_2/act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/bn2 (BatchNormalization (None, 20, 20, 192)  768         fire3_2/expand1x1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/act2 (Activation)       (None, 20, 20, 192)  0           fire3_2/bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/expand3x3 (Conv2D)      (None, 20, 20, 192)  331776      fire3_2/act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/bn3 (BatchNormalization (None, 20, 20, 192)  768         fire3_2/expand3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fire3_2/act3 (Activation)       (None, 20, 20, 192)  0           fire3_2/bn3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 20, 20, 384)  0           fire3_2/act2[0][0]               \n",
      "                                                                 fire3_2/act3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pred_conf (Conv2D)              (None, 20, 20, 1)    385         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pred_offset (Conv2D)            (None, 20, 20, 2)    770         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 20, 20, 3)    0           pred_conf[0][0]                  \n",
      "                                                                 pred_offset[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,761,283\n",
      "Trainable params: 1,756,419\n",
      "Non-trainable params: 4,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = create_loss_function(anchor_width,\n",
    "                         anchor_height,\n",
    "                         LABEL_WEIGHT,\n",
    "                         OFFSET_WEIGHT,\n",
    "                         OFFSET_LOSS_WEIGHT,\n",
    "                         EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loss() missing 1 required positional argument: 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7653ee441378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 342\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: loss() missing 1 required positional argument: 'y_pred'"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(lr=1e-4, decay=1e-4)\n",
    "model.compile(loss=l, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = data_generator(DATA_DIR, 2, WIDTH, HEIGHT, anchor_width, anchor_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, i = next(data_gen)\n",
    "print(l.shape)\n",
    "print(i.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
