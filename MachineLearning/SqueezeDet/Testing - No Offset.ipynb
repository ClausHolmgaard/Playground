{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SqueezeDetHelpers import fire_layer, binary_crossentropy, keras_binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/annot\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"./data\"\n",
    "ANNOTATION_FILE = r\"annot\"\n",
    "annotation = os.path.join(DATA_DIR, ANNOTATION_FILE)\n",
    "print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16\n",
    "\n",
    "BATCHSIZE = 4\n",
    "\n",
    "HEIGHT = 320\n",
    "WIDTH = 320\n",
    "CHANNELS = 3\n",
    "\n",
    "WEIGHT_DECAY = 1e-3\n",
    "KEEP_PROB = 0.5\n",
    "CLASSES = 1\n",
    "\n",
    "LABEL_WEIGHT = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (?, 320, 320, 3)\n",
      "conv1: (?, 160, 160, 128)\n",
      "pool1: (?, 80, 80, 128)\n",
      "fire1: (?, 80, 80, 256)\n",
      "fire2: (?, 80, 80, 256)\n",
      "pool2: (?, 40, 40, 256)\n",
      "fire3: (?, 40, 40, 392)\n",
      "fire4: (?, 40, 40, 392)\n",
      "up1: (?, 80, 80, 392)\n",
      "fire5: (?, 80, 80, 256)\n",
      "fire6: (?, 80, 80, 256)\n",
      "up2: (?, 160, 160, 256)\n",
      "fire7: (?, 160, 160, 256)\n",
      "fire8: (?, 160, 160, 256)\n",
      "up3: (?, 320, 320, 256)\n",
      "preds: (?, 320, 320, 1)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name=\"input\")\n",
    "print(f\"input: {input_layer.shape}\")\n",
    "\n",
    "conv1 = Conv2D(name='conv1', filters=128, kernel_size=(3, 3), strides=(2, 2), activation='relu', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(input_layer)\n",
    "print(f\"conv1: {conv1.shape}\")\n",
    "\n",
    "pool1 = MaxPool2D(name=\"pool1\", pool_size=(3, 3), strides=(2, 2), padding='SAME')(conv1)\n",
    "print(f\"pool1: {pool1.shape}\")\n",
    "\n",
    "fire1 = fire_layer(name=\"fire1\", input=pool1, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire1: {fire1.shape}\")\n",
    "\n",
    "fire2 = fire_layer(name=\"fire2\", input=fire1, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire2: {fire2.shape}\")\n",
    "\n",
    "pool2 = MaxPool2D(name=\"pool2\", pool_size=(3, 3), strides=(2, 2), padding='SAME')(fire2)\n",
    "print(f\"pool2: {pool2.shape}\")\n",
    "\n",
    "fire3 = fire_layer(name=\"fire3\", input=pool2, s1x1=48, e1x1=196, e3x3=196, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire3: {fire3.shape}\")\n",
    "\n",
    "fire4 = fire_layer(name=\"fire4\", input=fire3, s1x1=48, e1x1=196, e3x3=196, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire4: {fire4.shape}\")\n",
    "\n",
    "up1 = UpSampling2D(name=\"up1\", size=(2, 2), data_format=None, interpolation='nearest')(fire4)\n",
    "print(f\"up1: {up1.shape}\")\n",
    "\n",
    "fire5 = fire_layer(name=\"fire5\", input=up1, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire5: {fire5.shape}\")\n",
    "\n",
    "fire6 = fire_layer(name=\"fire6\", input=fire5, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire6: {fire6.shape}\")\n",
    "\n",
    "up2 = UpSampling2D(name=\"up2\", size=(2, 2), data_format=None, interpolation='nearest')(fire6)\n",
    "print(f\"up2: {up2.shape}\")\n",
    "\n",
    "fire7 = fire_layer(name=\"fire7\", input=up2, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire7: {fire7.shape}\")\n",
    "\n",
    "fire8 = fire_layer(name=\"fire8\", input=fire7, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire8: {fire8.shape}\")\n",
    "\n",
    "up3 = UpSampling2D(name=\"up3\", size=(2, 2), data_format=None, interpolation='nearest')(fire8)\n",
    "print(f\"up3: {up3.shape}\")\n",
    "\n",
    "\"\"\"\n",
    "conv1 = Conv2D(name='conv1', filters=128, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"SAME\",\n",
    "               #use_bias=True,\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY),\n",
    "               )(input_layer)\n",
    "print(f\"conv1: {conv1.shape}\")\n",
    "\n",
    "fire1 = fire_layer(name=\"fire1\", input=conv1, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire1: {fire1.shape}\")\n",
    "\n",
    "fire2 = fire_layer(name=\"fire2\", input=fire1, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire2: {fire2.shape}\")\n",
    "\n",
    "fire3 = fire_layer(name=\"fire3\", input=fire2, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire3: {fire3.shape}\")\n",
    "\n",
    "fire4 = fire_layer(name=\"fire4\", input=fire3, s1x1=32, e1x1=128, e3x3=128, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"fire4: {fire4.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "preds = Conv2D(name='preds',\n",
    "               filters=1,\n",
    "               kernel_size=(1, 1),\n",
    "               strides=(1, 1),\n",
    "               activation='sigmoid',\n",
    "               padding=\"SAME\",\n",
    "               kernel_initializer=TruncatedNormal(stddev=0.01),\n",
    "               kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(up3)\n",
    "print(f\"preds: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    # We are predicting a batchsize x anchorwidth x anchorheight x 3 output.\n",
    "    #c_predictions = y_pred[:, :, :, 0]\n",
    "    #c_labels = y_true[:, :, :, 0]\n",
    "\n",
    "    # number of labels\n",
    "    num_labels = K.sum(y_true)\n",
    "    num_non_labels = HEIGHT * WIDTH - num_labels\n",
    "    \n",
    "    # Loss matrix for all entries\n",
    "    loss_m_all = keras_binary_crossentropy(y_true, y_pred, EPSILON)\n",
    "    \n",
    "    # Loss matrix for the correct label\n",
    "    loss_m_label = keras_binary_crossentropy(y_true, y_pred, EPSILON) * y_true\n",
    "    \n",
    "    # Loss matrix for non labels\n",
    "    loss_m_nonlabel = loss_m_all - loss_m_label\n",
    "    \n",
    "    # Summing and adding weight to label loss\n",
    "    c_loss_label = K.sum(\n",
    "        loss_m_label\n",
    "    ) / num_labels\n",
    "    \n",
    "    # summing and adding weight to non label loss\n",
    "    c_loss_nonlabel = K.sum(\n",
    "        loss_m_nonlabel\n",
    "    ) / num_non_labels\n",
    "    \n",
    "    c_loss = c_loss_label * LABEL_WEIGHT + c_loss_nonlabel * (1 / LABEL_WEIGHT)\n",
    "    \n",
    "    total_loss = c_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    with open(annotation, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    gt = np.zeros((len(lines), WIDTH, HEIGHT))\n",
    "    \n",
    "    for l in lines:\n",
    "        obj = l.split(',')\n",
    "        pic_id = int(obj[0].split('.')[0])\n",
    "        x = int(obj[1])\n",
    "        y = int(obj[2])\n",
    "        \n",
    "        gt[pic_id, x, y] = 1.0\n",
    "\n",
    "    images = []\n",
    "    \n",
    "    for fi in os.listdir(DATA_DIR):\n",
    "        if not fi.endswith('jpg'):\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(DATA_DIR, fi)) / 255.0\n",
    "        images.append(im)\n",
    "    \n",
    "    return gt, np.array(images, dtype=np.float32)\n",
    "\n",
    "labels, images = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintInfo(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        decay = self.model.optimizer.decay\n",
    "        iterations = self.model.optimizer.iterations\n",
    "        lr_with_decay = lr / (1. + decay * K.cast(iterations, K.dtype(decay)))\n",
    "        print(f\"Learning rate with decay: {K.eval(lr_with_decay)}\")\n",
    "        #print(f\"lr={K.eval(lr)}, decay={K.eval(decay)}\")\n",
    "        print(\"\")\n",
    "        \n",
    "print_info = PrintInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 320, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 160, 160, 128 3584        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 80, 80, 128)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire1/squeeze1x1 (Conv2D)       (None, 80, 80, 32)   4128        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire1/expand1x1 (Conv2D)        (None, 80, 80, 128)  4224        fire1/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire1/expand3x3 (Conv2D)        (None, 80, 80, 128)  36992       fire1/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80, 80, 256)  0           fire1/expand1x1[0][0]            \n",
      "                                                                 fire1/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 80, 80, 32)   8224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 80, 80, 128)  4224        fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 80, 80, 128)  36992       fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 80, 80, 256)  0           fire2/expand1x1[0][0]            \n",
      "                                                                 fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 40, 40, 256)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 40, 40, 48)   12336       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 40, 40, 196)  9604        fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 40, 40, 196)  84868       fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 40, 40, 392)  0           fire3/expand1x1[0][0]            \n",
      "                                                                 fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 40, 40, 48)   18864       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 40, 40, 196)  9604        fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 40, 40, 196)  84868       fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 40, 40, 392)  0           fire4/expand1x1[0][0]            \n",
      "                                                                 fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up1 (UpSampling2D)              (None, 80, 80, 392)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 80, 80, 32)   12576       up1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 80, 80, 128)  4224        fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 80, 80, 128)  36992       fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 80, 80, 256)  0           fire5/expand1x1[0][0]            \n",
      "                                                                 fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 80, 80, 32)   8224        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 80, 80, 128)  4224        fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 80, 80, 128)  36992       fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 80, 80, 256)  0           fire6/expand1x1[0][0]            \n",
      "                                                                 fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up2 (UpSampling2D)              (None, 160, 160, 256 0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 160, 160, 32) 8224        up2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 160, 160, 128 4224        fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 160, 160, 128 36992       fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 160, 160, 256 0           fire7/expand1x1[0][0]            \n",
      "                                                                 fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 160, 160, 32) 8224        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 160, 160, 128 4224        fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 160, 160, 128 36992       fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 160, 160, 256 0           fire8/expand1x1[0][0]            \n",
      "                                                                 fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up3 (UpSampling2D)              (None, 320, 320, 256 0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "preds (Conv2D)                  (None, 320, 320, 1)  257         up3[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 520,881\n",
      "Trainable params: 520,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=1e-3, decay=1e-4) #, clipnorm=1.0)\n",
    "#opt = optimizers.RMSprop(lr=0.001)#,  clipnorm=1.0)\n",
    "#opt = optimizers.SGD(lr=1e-3, decay=1e-4, momentum=0.9, nesterov=False)\n",
    "#opt = optimizers.Adagrad(lr=1e-3, decay=1e-3, clipnorm=1.0)\n",
    "#opt =optimizers.SGD()\n",
    "model.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "10/10 [==============================] - 9s 905ms/step - loss: 3.9993\n",
      "Learning rate with decay: 0.0009997000452131033\n",
      "\n",
      "Epoch 2/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 3.9754\n",
      "Learning rate with decay: 0.0009994003921747208\n",
      "\n",
      "Epoch 3/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 3.9507\n",
      "Learning rate with decay: 0.00099910085555166\n",
      "\n",
      "Epoch 4/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 3.9230\n",
      "Learning rate with decay: 0.000998801551759243\n",
      "\n",
      "Epoch 5/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 3.8865\n",
      "Learning rate with decay: 0.000998502247966826\n",
      "\n",
      "Epoch 6/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 3.8314\n",
      "Learning rate with decay: 0.0009982032934203744\n",
      "\n",
      "Epoch 7/100000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 3.7412\n",
      "Learning rate with decay: 0.0009979044552892447\n",
      "\n",
      "Epoch 8/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 3.5866\n",
      "Learning rate with decay: 0.0009976057335734367\n",
      "\n",
      "Epoch 9/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 3.3178\n",
      "Learning rate with decay: 0.0009973073611035943\n",
      "\n",
      "Epoch 10/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.8725\n",
      "Learning rate with decay: 0.0009970089886337519\n",
      "\n",
      "Epoch 11/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.3090\n",
      "Learning rate with decay: 0.000996710965409875\n",
      "\n",
      "Epoch 12/100000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 2.2485\n",
      "Learning rate with decay: 0.000996412942185998\n",
      "\n",
      "Epoch 13/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.4508\n",
      "Learning rate with decay: 0.0009961151517927647\n",
      "\n",
      "Epoch 14/100000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 2.2528\n",
      "Learning rate with decay: 0.000995817594230175\n",
      "\n",
      "Epoch 15/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1769\n",
      "Learning rate with decay: 0.0009955201530829072\n",
      "\n",
      "Epoch 16/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1981\n",
      "Learning rate with decay: 0.0009952230611816049\n",
      "\n",
      "Epoch 17/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1894\n",
      "Learning rate with decay: 0.0009949259692803025\n",
      "\n",
      "Epoch 18/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1620\n",
      "Learning rate with decay: 0.0009946291102096438\n",
      "\n",
      "Epoch 19/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1602\n",
      "Learning rate with decay: 0.000994332367554307\n",
      "\n",
      "Epoch 20/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1816\n",
      "Learning rate with decay: 0.000994035741314292\n",
      "\n",
      "Epoch 21/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1888\n",
      "Learning rate with decay: 0.0009937394643202424\n",
      "\n",
      "Epoch 22/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1769\n",
      "Learning rate with decay: 0.0009934433037415147\n",
      "\n",
      "Epoch 23/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1665\n",
      "Learning rate with decay: 0.0009931473759934306\n",
      "\n",
      "Epoch 24/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1633\n",
      "Learning rate with decay: 0.0009928515646606684\n",
      "\n",
      "Epoch 25/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1616\n",
      "Learning rate with decay: 0.000992555869743228\n",
      "\n",
      "Epoch 26/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1604\n",
      "Learning rate with decay: 0.0009922604076564312\n",
      "\n",
      "Epoch 27/100000\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 2.1623\n",
      "Learning rate with decay: 0.0009919650619849563\n",
      "\n",
      "Epoch 28/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1664\n",
      "Learning rate with decay: 0.0009916700655594468\n",
      "\n",
      "Epoch 29/100000\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 2.1682\n",
      "Learning rate with decay: 0.0009913750691339374\n",
      "\n",
      "Epoch 30/100000\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 2.1669\n",
      "Learning rate with decay: 0.0009910804219543934\n",
      "\n",
      "Epoch 31/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1646\n",
      "Learning rate with decay: 0.0009907857747748494\n",
      "\n",
      "Epoch 32/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1630\n",
      "Learning rate with decay: 0.0009904912440106273\n",
      "\n",
      "Epoch 33/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1622\n",
      "Learning rate with decay: 0.0009901971789076924\n",
      "\n",
      "Epoch 34/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1624\n",
      "Learning rate with decay: 0.0009899029973894358\n",
      "\n",
      "Epoch 35/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1633\n",
      "Learning rate with decay: 0.0009896091651171446\n",
      "\n",
      "Epoch 36/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1643\n",
      "Learning rate with decay: 0.0009893154492601752\n",
      "\n",
      "Epoch 37/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1646\n",
      "Learning rate with decay: 0.0009890218498185277\n",
      "\n",
      "Epoch 38/100000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 2.1642\n",
      "Learning rate with decay: 0.0009887285996228456\n",
      "\n",
      "Epoch 39/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1636\n",
      "Learning rate with decay: 0.0009884353494271636\n",
      "\n",
      "Epoch 40/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1631\n",
      "Learning rate with decay: 0.0009881423320621252\n",
      "\n",
      "Epoch 41/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1629\n",
      "Learning rate with decay: 0.0009878494311124086\n",
      "\n",
      "Epoch 42/100000\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.1631\n",
      "Learning rate with decay: 0.0009875568794086576\n",
      "\n",
      "Epoch 43/100000\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 2.1634\n",
      "Learning rate with decay: 0.0009872643277049065\n",
      "\n",
      "Epoch 44/100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5f32033b20c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           callbacks=[print_info])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.fit(images.reshape(-1, 320, 320, 3), labels.reshape(-1, 2), batch_size=10, epochs=10, verbose=1)\n",
    "model.fit(images.reshape(-1, WIDTH, HEIGHT, 3),\n",
    "          labels.reshape(-1, WIDTH, HEIGHT, 1),\n",
    "          batch_size=BATCHSIZE,\n",
    "          epochs=100000,\n",
    "          verbose=1,\n",
    "          callbacks=[print_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass time: 0.05433082580566406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8818094"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECK_IMAGE_INDEX = 0\n",
    "\n",
    "before = time.time()\n",
    "res = model.predict(images[CHECK_IMAGE_INDEX].reshape(1, 320, 320, 3)).reshape(WIDTH, HEIGHT, 1)\n",
    "after = time.time()\n",
    "\n",
    "print(f\"Forward pass time: {after-before}\")\n",
    "\n",
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: 0.8845643997192383\n",
      "Number of values above or equal to 0.8845643997192383: 92404\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_res = np.copy(images[CHECK_IMAGE_INDEX])\n",
    "#print(np.max(im_res))\n",
    "#im_res *= 255.0\n",
    "#im_res = im_res.astype(np.uint8)\n",
    "\n",
    "max_val = np.max(res)\n",
    "print(f\"Max value: {max_val}\")\n",
    "above_val = max_val\n",
    "print(f\"Number of values above or equal to {above_val}: {np.count_nonzero(res[:, :, 0] >= above_val)}\")\n",
    "\n",
    "pred_indicies = np.where(res[:, :, 0] >= above_val)\n",
    "label_indices = np.where(labels[0])\n",
    "#print(pred_indicies)\n",
    "#print(label_indices)\n",
    "\n",
    "for (x, y) in zip(pred_indicies[0], pred_indicies[1]):\n",
    "    cv2.circle(im_res, (y, x), 1, (0, 1, 0), thickness=2)\n",
    "\n",
    "x_label = label_indices[0][0]\n",
    "y_label = label_indices[1][0]\n",
    "cv2.circle(im_res, (y_label, x_label), 1, (1.0, 0, 0), thickness=2)\n",
    "    \n",
    "f = plt.figure(figsize=(15, 8))\n",
    "plt.imshow(im_res)\n",
    "plt.title(\"Predicted in green, center in red.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
