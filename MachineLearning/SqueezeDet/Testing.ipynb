{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initially just some playing round with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Image<br>\n",
    "Initial output: center of hand<br>\n",
    "Is anchors needed? So the prediction is an offset?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D, Conv3D, Reshape, Dense, Flatten\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SqueezeDetHelpers import fire_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grid over image size\n",
    "    - Grid nodes will be anchors\n",
    "    - Net predicts: Probability of class at anchor, and offset from anchor.\n",
    "        - In later versions, several offsets will be predicted at each offset.\n",
    "- The net is fully convolutional, meaning the output must be feature maps.\n",
    "    - Amount of output filters will then be confidence+x_offset+y_offset\n",
    "    - filter size will be the size of the anchor grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/annot\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"./data\"\n",
    "ANNOTATION_FILE = r\"annot\"\n",
    "annotation = os.path.join(DATA_DIR, ANNOTATION_FILE)\n",
    "print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 320\n",
    "WIDTH = 320\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_DECAY = 0.001\n",
    "CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_HEIGHT = 78\n",
    "ANCHOR_WIDTH = 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out dim: 78x78\n",
      "Number of anchor nodes: 6084\n"
     ]
    }
   ],
   "source": [
    "num_anchor_nodes = ANCHOR_HEIGHT * ANCHOR_WIDTH\n",
    "\n",
    "print(f\"Out dim: {ANCHOR_HEIGHT}x{ANCHOR_WIDTH}\")\n",
    "print(f\"Number of anchor nodes: {num_anchor_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anchors: 6084\n",
      "Anchor dimension: (78, 78)\n",
      "Anchor shape: (78, 78, 2)\n"
     ]
    }
   ],
   "source": [
    "def set_anchors():\n",
    "    \n",
    "    #anchors = np.zeros((num_anchor_nodes, 2))\n",
    "    anchors = np.zeros((ANCHOR_HEIGHT, ANCHOR_WIDTH, 2))\n",
    "    print(f\"Number of anchors: {num_anchor_nodes}\")\n",
    "    \n",
    "    print(f\"Anchor dimension: ({ANCHOR_HEIGHT}, {ANCHOR_WIDTH})\")\n",
    "    print(f\"Anchor shape: {anchors.shape}\")\n",
    "    \n",
    "    #xs = np.arange(PIXELS_BETWEEN_ANCHORS, WIDTH, PIXELS_BETWEEN_ANCHORS)\n",
    "    #ys = np.arange(PIXELS_BETWEEN_ANCHORS, HEIGHT, PIXELS_BETWEEN_ANCHORS)\n",
    "    \n",
    "    x_start = WIDTH / (ANCHOR_WIDTH + 1)\n",
    "    x_end = WIDTH - x_start\n",
    "    y_start = HEIGHT / (ANCHOR_HEIGHT + 1)\n",
    "    y_end = HEIGHT - y_start\n",
    "    xs = np.linspace(x_start, x_end, num=ANCHOR_WIDTH)\n",
    "    ys = np.linspace(y_start, y_end, num=ANCHOR_HEIGHT)\n",
    "    \n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    for cx in range(len(xs)):\n",
    "        for cy in range(len(ys)):\n",
    "            anchors[counter] = [xs[cx], ys[cy]]\n",
    "            counter += 1\n",
    "    \"\"\"\n",
    "    \n",
    "    for ix in range(ANCHOR_HEIGHT):\n",
    "        for iy in range(ANCHOR_WIDTH):\n",
    "            anchors[ix, iy] = (xs[ix], ys[iy])\n",
    "    \n",
    "    return anchors\n",
    "    \n",
    "anchs = set_anchors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (?, 320, 320, 3)\n",
      "conv1: (?, 160, 160, 32)\n",
      "conv2: (?, 80, 80, 64)\n",
      "preds: (?, 78, 78, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nflat = Flatten()(conv2)\\n\\ndense1 = Dense(256,\\n               name='dense1',\\n               activation='relu')(flat)\\nprint(dense1.shape)\\n\\nout = Dense(2,\\n            name='out',\\n            activation='sigmoid')(flat)\\nprint(out.shape)\\n\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS), name=\"input\")\n",
    "print(f\"input: {input_layer.shape}\")\n",
    "\n",
    "conv1 = Conv2D(name='conv1', filters=32, kernel_size=(3, 3), strides=(2, 2), padding=\"SAME\", activation='relu',\n",
    "               #use_bias=True,\n",
    "               #kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY))\n",
    "               )(input_layer)\n",
    "print(f\"conv1: {conv1.shape}\")\n",
    "\n",
    "conv2 = Conv2D(name='conv2', filters=64, kernel_size=(3, 3), strides=(2, 2), activation=None, padding=\"SAME\",\n",
    "               #filters=len(ANCHORS),\n",
    "               #use_bias=True,\n",
    "               #kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(conv1)\n",
    "print(f\"conv2: {conv2.shape}\")\n",
    "\n",
    "preds = Conv2D(name='preds', filters=num_out, kernel_size=(3, 3), strides=(1, 1), activation='sigmoid', padding=\"VALID\",\n",
    "               #use_bias=True,\n",
    "               #kernel_initializer=TruncatedNormal(stddev=0.001),\n",
    "               #kernel_regularizer=l2(WEIGHT_DECAY)\n",
    "               )(conv2)\n",
    "print(f\"preds: {preds.shape}\")\n",
    "\n",
    "#pred_reshaped = Reshape((-1, 1))(preds)\n",
    "#print(pred_reshaped.shape)\n",
    "\"\"\"\n",
    "flat = Flatten()(conv2)\n",
    "\n",
    "dense1 = Dense(256,\n",
    "               name='dense1',\n",
    "               activation='relu')(flat)\n",
    "print(dense1.shape)\n",
    "\n",
    "out = Dense(2,\n",
    "            name='out',\n",
    "            activation='sigmoid')(flat)\n",
    "print(out.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross-entropy: q * -log(p) + (1-q) * -log(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_11:0\", shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def loss(y_pred, y_true):\n",
    "    # We are predicting a batchsize x anchorwidth x anchorheight x 3 output.\n",
    "    c_predictions = y_pred[:, :, :, 0]\n",
    "    c_labels = y_true[:, :, :, 0]\n",
    "    \n",
    "    y_pred_coords = y_pred[:, :, :, 1:]\n",
    "    y_true_coords = y_true[:, :, :, 1:]\n",
    "    \n",
    "    pred_conf = K.sigmoid(c_predictions)\n",
    "    \n",
    "    c_loss = K.sum(\n",
    "        (c_labels * (-K.log(pred_conf + EPSILON))) + (1-c_labels) * (-K.log(1-pred_conf + EPSILON))\n",
    "                  ) / BATCHSIZE\n",
    "    \n",
    "    l2_loss = K.sum(\n",
    "        K.pow(y_pred_coords - y_true_coords, 2)\n",
    "                    )\n",
    "    \n",
    "    total_loss = c_loss + l2_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "y_true_test = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "y_pred_test = np.zeros((BATCHSIZE, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "l = loss(y_pred_test, y_true_test)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.841361487904734\n"
     ]
    }
   ],
   "source": [
    "c_labels = 0\n",
    "c_predictions = 1\n",
    "c_loss = (c_labels * (-np.log(c_predictions + EPSILON))) + (1-c_labels) * (-np.log(1-c_predictions + EPSILON))\n",
    "print(c_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Model(inputs=input_layer, outputs=preds)\n",
    "#model.compile(loss='mse', optimizer='adam')\n",
    "#model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    with open(annotation, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    gt = [(None, None)] * len(lines)\n",
    "    \n",
    "    for l in lines:\n",
    "        obj = l.split(',')\n",
    "        pic_id = int(obj[0].split('.')[0])\n",
    "        x = int(obj[1])\n",
    "        y = int(obj[2])\n",
    "        \n",
    "        gt[pic_id] = (x, y)\n",
    "\n",
    "    images = []\n",
    "    \n",
    "    for fi in os.listdir(DATA_DIR):\n",
    "        if not fi.endswith('jpg'):\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(DATA_DIR, fi))\n",
    "        images.append(im)\n",
    "    \n",
    "    return gt, images\n",
    "\n",
    "labels_old, images_old = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 78, 3)\n",
      "1\n",
      "-4.1611531387577765e-05\n",
      "0.00027047495401925865\n",
      "[ 1.         -0.25316456  1.64556962]\n"
     ]
    }
   ],
   "source": [
    "def closest_anchor_map(x, y, anchor_coords):\n",
    "    \"\"\" Create a anchor_height x anchor_width x 3 map.\n",
    "        First entry is 1 if the anchor point is closest to true point. Zero otherwise.\n",
    "        Second is x offset.\n",
    "        Third is y offset. \"\"\"\n",
    "    closest = 10000\n",
    "    closest_x = None\n",
    "    closest_y = None\n",
    "    closest_x_offset = None\n",
    "    closest_y_offset = None\n",
    "    \n",
    "    res = np.zeros((ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    for ix in range(ANCHOR_HEIGHT):\n",
    "        for iy in range(ANCHOR_WIDTH):\n",
    "            p_x, p_y = anchor_coords[ix, iy]\n",
    "            dist = np.sqrt( (x - p_x)**2 + (y - p_y)**2 )\n",
    "            #res[ix, iy, 1:] = (x - p_x, y - p_y)\n",
    "            if dist < closest:\n",
    "                closest = dist\n",
    "                closest_x = ix\n",
    "                closest_y = iy\n",
    "                closest_x_offset = x - p_x\n",
    "                closest_y_offset = y - p_y\n",
    "    \n",
    "    #print(f\"({closest_x}, {closest_y}) -> {anchor_coords[closest_x, closest_y]}\")\n",
    "    res[closest_x, closest_y, 0] = 1\n",
    "    res[closest_x, closest_y, 1:] = (closest_x_offset, closest_y_offset)\n",
    "    \n",
    "    return res\n",
    "        \n",
    "test_map = closest_anchor_map(20, 30, anchs)\n",
    "print(test_map.shape)\n",
    "print(np.count_nonzero(test_map[:,:, 0]))\n",
    "print(np.mean(test_map[:, :, 1]))\n",
    "print(np.mean(test_map[:, :, 2]))\n",
    "print(test_map[4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 78, 78, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_data_with_anchors():\n",
    "    # load images\n",
    "    # labels will be:\n",
    "    #   anchor_height x anchor_width x 3\n",
    "    #     the last 3 entries is: 1 if closest gridpoint to a point. x and y offsets to closest point.\n",
    "    with open(annotation, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    gt = np.zeros((len(lines), ANCHOR_HEIGHT, ANCHOR_WIDTH, 3))\n",
    "    \n",
    "    for c, l in enumerate(lines):\n",
    "        obj = l.split(',')\n",
    "        pic_id = int(obj[0].split('.')[0])\n",
    "        x = int(obj[1])\n",
    "        y = int(obj[2])\n",
    "        \n",
    "        gt[c, :, :] = closest_anchor_map(x, y, anchs)\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for fi in os.listdir(DATA_DIR):\n",
    "        if not fi.endswith('jpg'):\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(DATA_DIR, fi))\n",
    "        images.append(im)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    \n",
    "    return gt, images\n",
    "        \n",
    "labels, images = load_data_with_anchors()\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = np.array(labels)#.reshape(1, 100, 2)\n",
    "#print(labels.shape)\n",
    "#print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c, i in enumerate(images):\n",
    "#    model.fit(i.reshape(1, 320, 320, 3), labels[c].reshape(1, 2), epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(images.reshape(-1, 320, 320, 3), labels.reshape(-1, 2), batch_size=10, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def loss(y_true, y_pred):\n",
    "#    return K.sqrt(K.sum(K.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=preds)\n",
    "opt = optimizers.Adam(lr=0.0001)\n",
    "#opt =optimizers.SGD()\n",
    "model.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 10237.2062\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 9707.5189\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 9172.3816\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 8712.6636\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 8345.0337\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8055.4682\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7828.6585\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7650.0774\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7509.0698\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7396.0945\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7304.1908\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7227.2257\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 7163.0994\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7108.6739\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7062.6396\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7022.1184\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6988.7222\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6957.8296\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6931.1079\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6906.5308\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6885.6469\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 6867.0044\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6849.4340\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6833.6475\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6819.4439\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 6806.5721\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 6795.4661\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 6784.0761\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 6774.3855\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 6765.2947\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 6757.1486\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 6748.8858\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 6741.6048\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 6734.3368\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6728.3848\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6722.0297\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6716.3871\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 6711.7683\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 6707.1742\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6702.2145\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6698.1344\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6693.4971\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6689.4204\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6686.1497\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6683.3073\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6679.2602\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6676.2811\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6673.4023\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6670.9331\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6668.0388\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6665.2283\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6663.0826\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6660.4585\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6658.5882\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6656.1307\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6654.7027\n",
      "Epoch 57/100\n"
     ]
    }
   ],
   "source": [
    "#model.fit(images.reshape(-1, 320, 320, 3), labels.reshape(-1, 2), batch_size=10, epochs=10, verbose=1)\n",
    "model.fit(images.reshape(-1, 320, 320, 3),\n",
    "          labels.reshape(-1, ANCHOR_HEIGHT, ANCHOR_WIDTH, 3),\n",
    "          batch_size=16,\n",
    "          epochs=100,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 65  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0]\n",
      "(78, 78, 3)\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(images[1].reshape(1, 320, 320, 3)).reshape(78, 78, 3)\n",
    "print(np.argmax(labels[1, :, :, 0], axis=0))\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(res[:,:,0] == res[:,:,0].max())\n",
    "res[26, 29, 0]\n",
    "res[27, 39, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "31\n",
      "2057\n"
     ]
    }
   ],
   "source": [
    "print(np.max(res[:, :, 0]))\n",
    "print(np.count_nonzero(res[:, :, 0] > 0.9))\n",
    "print(np.argmax(res[:, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_encode_gt(num_data, gt):\n",
    "    gt_ohe = np.zeros((num_data, num_output))\n",
    "    print(gt_ohe.shape)\n",
    "    \n",
    "    lowest_index = [0, 0]\n",
    "    for c, i in enumerate(gt):\n",
    "        \n",
    "        np.sqrt(np.sum(np.square(  )))\n",
    "        \n",
    "ohe_encode_gt(len(labels), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
