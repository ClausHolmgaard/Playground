{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "89jDwMa9XR0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b831539f-8b4e-4bee-b4d3-4a51bab06ed5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense, LeakyReLU, Conv2DTranspose, Reshape, Activation\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.callbacks import Callback, LearningRateScheduler\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "import os\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGLXsEAzfBal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bit ugly, but works for now\n",
        "try:\n",
        "  os.listdir('/content/gdrive/My Drive/')\n",
        "except:\n",
        "  drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSnf3r2qeaaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1adb2122-c89d-434e-8086-d30188f1a0b0"
      },
      "source": [
        "save_path = '/content/gdrive/My Drive/data/models/'\n",
        "model_name = 'autoencoder_mnist_basic_10_1_latent'\n",
        "model_save_path = save_path + model_name + '_model.kerasmodel'\n",
        "weights_save_path = save_path + model_name + '_weights.h5'\n",
        "print(f\"model save path: {model_save_path}\")\n",
        "print(f\"weights save path: {weights_save_path}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model save path: /content/gdrive/My Drive/data/models/autoencoder_mnist_basic_10_1_latent_model.kerasmodel\n",
            "weights save path: /content/gdrive/My Drive/data/models/autoencoder_mnist_basic_10_1_latent_weights.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyYcJ4ZyXR0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_test = x_test.reshape(x_test.shape + (1,))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AOYfDPXXR0Z",
        "colab_type": "text"
      },
      "source": [
        "Create encoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX0NVpdgXR0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "763047ba-cd11-46f1-e66f-327accf27288"
      },
      "source": [
        "encoder_input = Input((28, 28, 1))\n",
        "\n",
        "e = Conv2D(\n",
        "    filters=32,\n",
        "    kernel_size=3,\n",
        "    strides=1,\n",
        "    padding='same'\n",
        "    )(encoder_input)\n",
        "e = LeakyReLU()(e)\n",
        "\n",
        "e = Conv2D(\n",
        "    filters=64,\n",
        "    kernel_size=3,\n",
        "    strides=2,\n",
        "    padding='same'\n",
        "    )(e)\n",
        "e = LeakyReLU()(e)\n",
        "\n",
        "e = Conv2D(\n",
        "    filters=64,\n",
        "    kernel_size=3,\n",
        "    strides=2,\n",
        "    padding='same'\n",
        "    )(e)\n",
        "e = LeakyReLU()(e)\n",
        "\n",
        "e = Conv2D(\n",
        "    filters=64,\n",
        "    kernel_size=3,\n",
        "    strides=1,\n",
        "    padding='same'\n",
        "    )(e)\n",
        "e = LeakyReLU()(e)\n",
        "\n",
        "shape_before_flattening = K.int_shape(e)[1:]\n",
        "\n",
        "e = Flatten()(e)\n",
        "encoder_output = Dense(10)(e)\n",
        "\n",
        "encoder_model = Model(encoder_input, encoder_output)\n",
        "\n",
        "encoder_model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                31370     \n",
            "=================================================================\n",
            "Total params: 124,042\n",
            "Trainable params: 124,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zPgf-XQ9E7Z",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgBakS4XR0d",
        "colab_type": "text"
      },
      "source": [
        "Create decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AqjmSYfXR0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "54f557d7-96e1-4131-ba9b-862c1018ae9e"
      },
      "source": [
        "decoder_input = Input((10,))\n",
        "\n",
        "d = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "d = Reshape(shape_before_flattening)(d)\n",
        "\n",
        "d = Conv2DTranspose(\n",
        "    filters=64,\n",
        "    kernel_size=3,\n",
        "    strides=1,\n",
        "    padding='same'\n",
        "    )(d)\n",
        "d = LeakyReLU()(d)\n",
        "\n",
        "d = Conv2DTranspose(\n",
        "    filters=64,\n",
        "    kernel_size=3,\n",
        "    strides=2,\n",
        "    padding='same'\n",
        "    )(d)\n",
        "d = LeakyReLU()(d)\n",
        "\n",
        "d = Conv2DTranspose(\n",
        "    filters=32,\n",
        "    kernel_size=3,\n",
        "    strides=2,\n",
        "    padding='same'\n",
        "    )(d)\n",
        "d = LeakyReLU()(d)\n",
        "\n",
        "d = Conv2DTranspose(\n",
        "    filters=1,\n",
        "    kernel_size=3,\n",
        "    strides=1,\n",
        "    padding='same'\n",
        "    )(d)\n",
        "d = Activation('sigmoid')(d)\n",
        "\n",
        "decoder_output = d\n",
        "\n",
        "decoder_model = Model(decoder_input, decoder_output)\n",
        "\n",
        "decoder_model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3136)              34496     \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        18464     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         289       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 127,105\n",
            "Trainable params: 127,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1Duk6CpXR0g",
        "colab_type": "text"
      },
      "source": [
        "Full autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POk6tF3YXR0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ae_input = encoder_input\n",
        "ae_output = decoder_model(encoder_output)\n",
        "\n",
        "ae_model = Model(ae_input, ae_output)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ocb2pb0XR0j",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jcuX7bwXR0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "LEARNING_RATE_DECAY = 1\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "INITIAL_EPOCH = 0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkhb91znXR0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def r_loss(y_true, y_pred):\n",
        "    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0ZUC4F4XR0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr=LEARNING_RATE)\n",
        "ae_model.compile(optimizer=optimizer, loss=r_loss)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhV9ae0ngafO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def step_decay_schedule(initial_lr, decay_factor=0.5, step_size=1):\n",
        "    def schedule(epoch):\n",
        "        new_lr = initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
        "        return new_lr\n",
        "\n",
        "    return LearningRateScheduler(schedule)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4j9mhZGi8sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomCallback(Callback):    \n",
        "    def __init__(self):\n",
        "        self.losses = []\n",
        "        self.lrs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        #keys = list(logs.keys())\n",
        "        #print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
        "        self.lrs.append(logs['lr'])\n",
        "        self.losses.append(logs['loss'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKuWRLMif6Sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_sched = step_decay_schedule(initial_lr=LEARNING_RATE, decay_factor=LEARNING_RATE_DECAY, step_size=1)\n",
        "checkpoint = ModelCheckpoint(weights_save_path, save_weights_only=True, verbose=0)\n",
        "cb = CustomCallback()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8kMH72YXR0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e669a90d-9a24-4a3f-a96a-9eddc467fbca"
      },
      "source": [
        "ae_model.fit(     \n",
        "    x_train,\n",
        "    x_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    epochs=EPOCHS,\n",
        "    initial_epoch=INITIAL_EPOCH,\n",
        "    callbacks=[lr_sched, checkpoint, cb]\n",
        "    )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 15s 244us/step - loss: 0.0269\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0158\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 13s 215us/step - loss: 0.0145\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0137\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0132\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0127\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0124\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0121\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0119\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0117\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0115\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0114\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0112\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0111\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0110\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0109\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0108\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0107\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0106\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0106\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0105\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0104\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0104\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0103\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0103\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0102\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0102\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0101\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0101\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0101\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0100\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0100\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0099\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0099\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0099\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0098\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0098\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0098\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0098\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0097\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0097\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0097\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0097\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0096\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0096\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0096\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0096\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0095\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0095\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0095\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0095\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0095\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0094\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0094\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0094\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0094\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 13s 215us/step - loss: 0.0094\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0094\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 13s 208us/step - loss: 0.0093\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0093\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0093\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0093\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0093\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0093\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 13s 217us/step - loss: 0.0093\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0092\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0092\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0092\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0092\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0092\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0092\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0092\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0092\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0091\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0091\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0091\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0091\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0091\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0091\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0091\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0091\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0091\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0091\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0090\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0090\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0090\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0090\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0090\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0090\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0090\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0090\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0090\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0090\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0090\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0089\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0089\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0089\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0089\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0089\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0089\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0089\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0089\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 13s 215us/step - loss: 0.0089\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0089\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0089\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0089\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0089\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0089\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0088\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0088\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0088\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0088\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0088\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0088\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0088\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0088\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0088\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0088\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0088\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 13s 216us/step - loss: 0.0088\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0088\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0088\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0088\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0088\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0088\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0088\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0088\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0087\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0087\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 13s 215us/step - loss: 0.0087\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0087\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0087\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0087\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0087\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0087\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0087\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0087\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0087\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0087\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0087\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0087\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0087\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0087\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 13s 215us/step - loss: 0.0087\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0087\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0087\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 13s 217us/step - loss: 0.0087\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0087\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0087\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0087\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0086\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0086\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 13s 217us/step - loss: 0.0086\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0086\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0086\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0086\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0086\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0086\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0086\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0086\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0086\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0086\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0086\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0086\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0086\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0086\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0086\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0086\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0086\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0086\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0086\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0086\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0086\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0086\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0086\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0086\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0086\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0086\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0086\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 12s 200us/step - loss: 0.0086\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0086\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0086\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0085\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0085\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 13s 208us/step - loss: 0.0085\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0085\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0085\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0085\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0085\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 13s 217us/step - loss: 0.0085\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0085\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0085\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0085\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0085\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0085\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0085\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0085\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0085\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0085\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f9d91751198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rMphrTfZ6jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ae_model.save(model_save_path)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuW5J08WaPLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a274dfd1-66af-456c-d4f3-a10094df8c3a"
      },
      "source": [
        "plt.plot(cb.losses)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9d80019208>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}